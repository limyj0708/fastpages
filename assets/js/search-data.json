{
  
    
        "post0": {
            "title": "Ubuntu 새 유저 SSH key 추가",
            "content": "1. &#48176;&#44221; . Oracle Free tier에서 Ubuntu instance를 만들면, 기본 계정명이 ubuntu다. 계정을 새로 만들면, 처음에 생성했던 SSH key로는 접속이 되지 않는다. | . | key를 새로 만든 후에, instance에 등록해보자. | . 2. &#49352; &#44228;&#51221; &#49373;&#49457; . sudo adduser limyj0708 : limyj0708 계정 생성 password 설정 진행 | 몇 가지 정보 적당히 씀 (Full_name 등) | . | sudo usermod -aG sudo limyj0708 : sudo 그룹을 limyj0708에 추가하여 sudo 명령어를 사용 가능하게 세팅 | . 3. SSH key &#49373;&#49457; . ssh-keygen -t rsa -N &quot;원하는 password&quot; -b 2048 -C &quot;원하는 comment&quot; -f &quot;원하는 file path&quot; . byte는 최소 2048로 진행 | file path에 지정한 경로, 이름으로 공개키와 비밀키가 생성된다. | . 4. instance&#50640; SSH key &#46321;&#47197; . local이 리눅스면 ssh-copy-id를 쓰고, 윈도우에서도 해당 명령어에 대응하는 powershell 명령어가 있던데, 솔직히 잘 안 되었다. 권한 문제 뜨고. | 그래서 수동으로 추가하기로 한다. | . 새로 생성한 계정에서는 처음에 /.ssh 폴더가 없다. 생성해줘야 한다. | ubuntu 계정으로 접속 sudo su : root 계정으로 변경 | mkdir /home/limyj0708/.ssh : .ssh 폴더 생성 | nano /home/limyj0708/.ssh/authorized_keys : authorized_keys 파일도 없어서 새로 생성된다. 이제 위에서 생성했던 공개키의 내용을 붙여넣고 저장한다. | . | | 5. instance&#50640; &#51217;&#49549; . Openssh 윈도우에서도 잘 되니까, Powershell에서 아래 명령어로 접속한다. . ssh -i &quot;비밀키 경로&quot; limyj0708@서버ip . | Profit! . | .",
            "url": "https://limyj0708.github.io/fastpages/linux/2022/07/05/Ubuntu-%EC%83%88-%EC%9C%A0%EC%A0%80-SSH-key-%EC%B6%94%EA%B0%80.html",
            "relUrl": "/linux/2022/07/05/Ubuntu-%EC%83%88-%EC%9C%A0%EC%A0%80-SSH-key-%EC%B6%94%EA%B0%80.html",
            "date": " • Jul 5, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Git CheatSheet",
            "content": "1. &#44592;&#51316; &#46356;&#47113;&#53664;&#47532;&#47484; Git &#51200;&#51109;&#49548;&#47196; &#47564;&#46308;&#44592; . 원하는 폴더로 이동 후 git init | . 2. &#44592;&#51316; &#51200;&#51109;&#49548;&#47484; Clone &#54616;&#44592; . fastpage repository를 clone 한다면 | git clone https://github.com/limyj0708/fastpages.git | . 3. &#49688;&#51221;&#44284; &#51200;&#51109; . . 3-1. &#49345;&#53468; &#54869;&#51064; . git status | . PS C: Users limyj0708 fastpages&gt; git status On branch master Your branch is up to date with &#39;origin/master&#39;. Untracked files: (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) _notebooks/2022-06-13-git_cheatsheet.ipynb nothing added to commit but untracked files present (use &quot;git add&quot; to track) . 2022-06-13-git_cheatsheet.ipynb 파일이 untracked 상태 | Git은 Untracked 파일을 아직 스냅샷(커밋)에 넣어지지 않은 파일이라고 본다. 파일이 Tracked 상태가 되기 전까지는 Git은 절대 그 파일을 커밋하지 않는다. 그래서 일하면서 생성하는 바이너리 파일 같은 것을 커밋하는 실수는 하지 않게 된다. | . 3-2. &#54028;&#51068;&#51012; &#49352;&#47196; &#52628;&#51201;&#54616;&#44592; . git add _notebooks/2022-06-13-git_cheatsheet.ipynb | 이후 다시 status를 보면 | . PS C: Users limyj0708 fastpages&gt; git status On branch master Your branch is up to date with &#39;origin/master&#39;. Changes to be committed: (use &quot;git restore --staged &lt;file&gt;...&quot; to unstage) new file: _notebooks/2022-06-13-git_cheatsheet.ipynb . “Changes to be committed” 에 들어 있는 파일은 Staged 상태라는 것을 의미한다. 커밋하면 git add 를 실행한 시점의 파일이 커밋되어 저장소 히스토리에 남는다. | git add 명령은 파일 또는 디렉토리의 경로를 아규먼트로 받는다. 디렉토리면 아래에 있는 모든 파일들까지 재귀적으로 추가한다. | . 3-3. Modified &#49345;&#53468;&#51032; &#54028;&#51068;&#51012; Stage &#54616;&#44592; . 2022-06-13-git_cheatsheet.ipynb를 수정한 후에 git status를 해 보면? | . On branch master Your branch is up to date with &#39;origin/master&#39;. Changes to be committed: (use &quot;git restore --staged &lt;file&gt;...&quot; to unstage) new file: _notebooks/2022-06-13-git_cheatsheet.ipynb Changes not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git restore &lt;file&gt;...&quot; to discard changes in working directory) modified: _notebooks/2022-06-13-git_cheatsheet.ipynb . “Changes not staged for commit” 에 있다. 이것은 수정한 파일이 Tracked 상태이지만 아직 Staged 상태는 아니라는 것이다. Staged 상태로 만들려면 git add 명령을 실행해야 한다. git add 명령은 파일을 새로 추적할 때도 사용하고 수정한 파일을 Staged 상태로 만들 때도 사용한다. Merge 할 때 충돌난 상태의 파일을 Resolve 상태로 만들때도 사용한다. add의 의미는 프로젝트에 파일을 추가한다기 보다는 다음 커밋에 추가한다고 받아들이는게 좋다. . | git add _notebooks/2022-06-13-git_cheatsheet.ipynb후 다시 git status를 해 보자. . | . PS C: Users limyj0708 fastpages&gt; git status On branch master Your branch is up to date with &#39;origin/master&#39;. Changes to be committed: (use &quot;git restore --staged &lt;file&gt;...&quot; to unstage) new file: _notebooks/2022-06-13-git_cheatsheet.ipynb . “Changes to be committed”에 잘 들어갔는데, 여기서 또 수정을 하고 git status를 하면? | . PS C: Users limyj0708 fastpages&gt; git status On branch master Your branch is up to date with &#39;origin/master&#39;. Changes to be committed: (use &quot;git restore --staged &lt;file&gt;...&quot; to unstage) new file: _notebooks/2022-06-13-git_cheatsheet.ipynb Changes not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git restore &lt;file&gt;...&quot; to discard changes in working directory) modified: _notebooks/2022-06-13-git_cheatsheet.ipynb . Changes to be committed / Changes not staged for commit에 둘 다 2022-06-13-git_cheatsheet.ipynb이 들어있는 이유 지금 이 시점에서 커밋을 하면 git commit 명령을 실행하는 시점의 버전이 커밋되는 것이 아니라 마지막으로 git add 명령을 실행했을 때의 버전이 커밋된다. 그러니까 git add 명령을 실행한 후에 또 파일을 수정하면 git add 명령을 다시 실행해서 최신 버전을 Staged 상태로 만들어야 한다. | . | . 3-4. &#54028;&#51068; &#49345;&#53468;&#47484; &#51684;&#47561;&#54616;&#44172; &#54869;&#51064;&#54616;&#44592; . test | .",
            "url": "https://limyj0708.github.io/fastpages/git/2022/06/13/git_cheatsheet.html",
            "relUrl": "/git/2022/06/13/git_cheatsheet.html",
            "date": " • Jun 13, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Python Google Drive API v3로 파일 업로드",
            "content": "1. google api &#54056;&#53412;&#51648; &#49444;&#52824; . !pip3 install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib . 2. Credential &#49464;&#54021; &#54980; &#49892;&#54665; . https://console.cloud.google.com/ 접속 | 원하는 프로젝트 선택 | API &amp; Services Enabled APIs &amp; Services에서 Google Drive API 활성화 | Credentials Create Credentials -&gt; OAuth client ID 생성 service account를 사용하고 싶었으나, 대상 폴더가 회사 조직 내 계정이 아니면 공유가 되지 않는 폴더여서 service account 사용이 불가능 | 가능한 상황이면, service account를 대상 폴더의 편집자로 추가하는 편이, 더 보안상 좋다. | . | Download OAuth Client clinet-secret JSON 파일이 받아진다. | . | | | https://developers.google.com/drive/api/quickstart/python quickstart 스크립트를 적절하게 바꾸어서 실행한다. | 최초로 실행하면 로그인 과정 후에 token.json이 생성되고, 이후에는 token.json을 읽어서 실행된다. | 아래 스크립트는 xlsx 파일 하나를 원하는 폴더에 업로드 하는 스크립트이다. | | import os.path from google.auth.transport.requests import Request from google.oauth2.credentials import Credentials from google_auth_oauthlib.flow import InstalledAppFlow from googleapiclient.discovery import build from googleapiclient.errors import HttpError # If modifying these scopes, delete the file token.json. # SCOPES = [&#39;https://www.googleapis.com/auth/drive.file&#39;] def main(): &quot;&quot;&quot;Shows basic usage of the Drive v3 API. Prints the names and ids of the first 10 files the user has access to. &quot;&quot;&quot; creds = None # The file token.json stores the user&#39;s access and refresh tokens, and is # created automatically when the authorization flow completes for the first # time. if os.path.exists(&#39;token.json&#39;): creds = Credentials.from_authorized_user_file(&#39;token.json&#39;, SCOPES) # If there are no (valid) credentials available, let the user log in. if not creds or not creds.valid: if creds and creds.expired and creds.refresh_token: creds.refresh(Request()) else: flow = InstalledAppFlow.from_client_secrets_file(&#39;Download OAuth Clinet에서 받은 client-secret JSON 파일&#39;, SCOPES) creds = flow.run_local_server(port=0) # Save the credentials for the next run with open(&#39;token.json&#39;, &#39;w&#39;) as token: token.write(creds.to_json()) try: # 원하는 작업 코드 작성 # 이 경우에는, xlsx 파일 하나를 원하는 폴더에 업로드 folder_id = &#39;원하는 폴더 ID&#39; service = build(&#39;drive&#39;, &#39;v3&#39;, credentials=creds) file_metadata = {&#39;name&#39;: &#39;quest_main_join_string_name.xlsx&#39;,&#39;parents&#39;: [folder_id]} media = MediaFileUpload(&#39;quest_main_join_string_name.xlsx&#39;, mimetype=None, resumable=True) # 파일이 커질 것 같으면 resumable을 켜 주는 것이 좋다. file = service.files().create(body=file_metadata,media_body=media,fields=&#39;id&#39;).execute except HttpError as error: # TODO(developer) - Handle errors from drive API. print(f&#39;An error occurred: {error}&#39;) if __name__ == &#39;__main__&#39;: main() .",
            "url": "https://limyj0708.github.io/fastpages/python/2022/05/26/Python-Google-Drive-API-v3%EB%A1%9C-%ED%8C%8C%EC%9D%BC-%EC%97%85%EB%A1%9C%EB%93%9C.html",
            "relUrl": "/python/2022/05/26/Python-Google-Drive-API-v3%EB%A1%9C-%ED%8C%8C%EC%9D%BC-%EC%97%85%EB%A1%9C%EB%93%9C.html",
            "date": " • May 26, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Jupyter Lab Server 세팅",
            "content": ". CentOS에 Jupyter Lab 설치가 완료되었다고 가정하자. 구글에 Jupyter lab server라고 검색하면, 아래 페이지가 가장 먼저 뜨게 되는데, 이 페이지 말고 https://jupyter-notebook.readthedocs.io/en/stable/public_server.html | . | 이 페이지를 확인하는 것이 좋다. https://jupyter-server.readthedocs.io/en/latest/operators/public-server.html | . | . | . 1. Jupyter server configuration &#54028;&#51068; &#49444;&#51221; . jupyter server --generate-config를 하면, /home/&quot;유저이름&quot;/.jupyter/jupyter_server_config.py가 생성된다. 여기에서 세팅을 해야 한다. c.ServerApp.open_browser = False (브라우저 띄우지 않음) | c.ServerApp.password = &#39;argon2...&#39; from jupyter_server.auth import passwd; passwd()를 실행하여 생성하는, 암호화된 비밀번호를 입력한다. | . | c.ServerApp.port = 원하는 포트 | c.ServerApp.certfile = openssl로 만든 certfile 등록 (예: mycert.pem) | c.ServerApp.keyfile = openssl로 만든 keyfile 등록 (예: mykey.key) | c.ServerApp.ip = &#39;*&#39;, 혹은 접근 가능하게 하고싶은 ip | c.ServerApp.root_dir = 원하는 경로 notebook_dir is deprecated, use root_dir | . | c.ServerApp.allow_origin = &#39;*&#39; Use &#39;*&#39; to allow any origin to access your server. | . | . | 2. &#47928;&#51228;&#51216;&#44284; &#54644;&#44208; . self-signed certificate 오류 메세지 openssl req -x509 -nodes -days 999 -newkey rsa:2048 -keyout mykey.key -out mycert.pem 이런 식으로 만든 self-signed certificate를 쓰면 jupyter lab 실행 시, 뭘 하기만 하면 SSL Error를 띄운다. 이런 식으로 : SSL Error on 13 (&#39;ip&#39;, 13786): [SSL: SSLV3_ALERT_CERTIFICATE_UNKNOWN] sslv3 alert certificate unknown (_ssl.c:997) | Safari에서는 안 뜨고, Edge에서는 뜨는 걸로 봐서 크로미움 기반 브라우저에서 접속하면 뜨는 것 같다. | . | . Let&#39;s Encrypt 같은 서비스를 이용해서 인증서를 받아도 되는데, 도메인 네임도 없는, 혼자 쓰는 무료 클라우드 서버에서 그렇게까지 해야 하나 싶다. | tmux에서 새 pane을 만들고, jupyter lab &gt; /dev/null 2&gt;&amp;1 &amp;으로 jupyter lab을 실행하여 콘솔 output을 없애고 백그라운드에서 jupyter lab을 실행하자. | | |",
            "url": "https://limyj0708.github.io/fastpages/jupyterlab/2022/05/26/Jupyter-Lab-Server-%EC%84%B8%ED%8C%85.html",
            "relUrl": "/jupyterlab/2022/05/26/Jupyter-Lab-Server-%EC%84%B8%ED%8C%85.html",
            "date": " • May 26, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "맥 OS pyenv 세팅 101",
            "content": "1. brew &#49444;&#52824; . https://brew.sh 확인하여 설치 | 설치 후 ~/.zprofile에 eval &quot;$(/opt/homebrew/bin/brew shellenv)&quot; 추가 다 설치하면 맨 마지막에 안내문으로 추가하라고 나오니 따라하기만 하자. | . | . 2. pyenv &#49444;&#52824; . brew install pyenv : 설치가 끝났다면... .zshrc에 eval &quot;$(pyenv init -)&quot; 추가 | .zprofile에 eval &quot;$(pyenv init --path)&quot; 추가 | . | . 3. pyenv&#47196; &#50896;&#54616;&#45716; &#54028;&#51060;&#50028; &#48260;&#51204; &#49444;&#52824; . pyenv install -list : 설치가능한 파이썬 버전 목록 확인 | pyenv install 3.10.3 : 예) 3.10.3 버전 설치 | . 4. pyenv-virtualenv &#49444;&#52824; . brew install pyenv-virtualenv .zshrc에 eval &quot;$(pyenv virtualenv-init -)&quot; 추가 | . | . 5. pyenv&#47196; &#44032;&#49345;&#54872;&#44221; &#49373;&#49457; . pyenv virtualenv [파이썬 버전] [가상환경 이름] 예) pyenv virtualenv 3.10.3 requests-3.10.3 | . | pyenv versions : 생성한 가상환경이 추가되었음을 알 수 있음 | . 6. &#44032;&#49345;&#54872;&#44221; on/off . 직접 on/off pyenv activate requests-3.10.3 실행하면 아래와 같은 메세지가 출력된다. | pyenv-virtualenv: prompt changing will be removed from future release. configure &quot;export PYENV_VIRTUALENV_DISABLE_PROMPT=1&quot; to simulate the behavior | 곧 이 기능은 사라질 모양이다. | . | pyenv deactivate | . | shell의 세션이 유지되는 동안 가상환경 유지 pyenv shell requests-3.10.3 | . | 원하는 폴더에 가서 실행하면, 이후 shell에서 해당 폴더로 가면 자동으로 원하는 가상환경이 켜지게 됨 (.python-version 파일이 해당 폴더에 생성) pyenv local requests-3.10.3 | pyenv local system : 다시 기본 시스템 버전으로 돌리고 싶을 때 | 해당 폴더에서 나가면 자동으로 기본 환경으로 돌아가게 된다. 편리하네! | . | 전체 적용 pyenv global requests-3.10.3 | pyenv global system : 다시 기본 시스템 버전으로 돌리고 싶을 때 | . | .",
            "url": "https://limyj0708.github.io/fastpages/python/2022/03/19/%EB%A7%A5-OS-pyenv-%EC%84%B8%ED%8C%85-101.html",
            "relUrl": "/python/2022/03/19/%EB%A7%A5-OS-pyenv-%EC%84%B8%ED%8C%85-101.html",
            "date": " • Mar 19, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "리눅스 Shell 명령어 Python 스크립트에서 실행하기 + Crontab",
            "content": "1. &#48176;&#44221; . 회사에 업무를 위한 소형 개인 서버로 쓰는 NUC가 있다. ssh로 연결하여 사용 | . | 사내 와이파이에 연결되어 있는데, 아주 가끔씩 할당된 IP가 바뀐다. | 이럴 때마다 모니터를 연결해서 ifconfig로 ip 주소를 확인할 수는 없는 노릇이다. | 일주일에 한 번씩, 서버가 나에게 현재 자신의 ip가 뭔지 보내줬으면 좋겠다. | . 2. &#49892;&#54665; . 1. Shell &#47749;&#47161;&#50612; . ifconfig [원하는 네트워크 인터페이스명] | grep -Eo &#39;([0-9]{1,3}[ .]){3}[0-9]{1,3}&#39; . grep -E : 표현을 확장 정규 표현식으로 해석 | -o : 매칭되는 문자열만 표시 | . | . 2. Python &#49828;&#53356;&#47549;&#53944;&#50640;&#49436; . import subprocess import requests regex_ipv4 = &#39;([0-9]{1,3}[ .]){3}[0-9]{1,3}&#39; #ipv4를 추출하는 정규식 ps = subprocess.Popen((&quot;ifconfig&quot;, &quot;원하는 네트워크 인터페이스명&quot;), stdout=subprocess.PIPE) output = subprocess.check_output((&quot;grep&quot;, &quot;-Eo&quot;, regex_ipv4), stdin=ps.stdout) ps.wait() ipv4_internal = str(output).split(&#39; n&#39;)[0][2:] # 사내에서 접근 가능한 IP주소만 추출함 TARGET_URL = &#39;https://notify-api.line.me/api/notify&#39; TOKEN = &#39;라인 Notify에서 발급받은 토큰 입력&#39; # 요청합니다. response = requests.post( TARGET_URL, headers={ &#39;Authorization&#39;: &#39;Bearer &#39; + TOKEN }, data={ &#39;message&#39;: f&#39;NUC IP : {ipv4_internal}&#39; } ) . Shell에서처럼 Pipe(|)를 쓸 수 없다. Popen에 shell=True를 넘겨주면 되긴 하는데, 일반적으로 shell에서 명령을 내리는 것 처럼 별도의 유효성 검사 없이 실행이 되기 때문에 shell injection에 취약하게 된다. | . | 그래서 쪼개서 실행시켜야 한다. Popen으로 ifconfig를 실행시키고, 그 출력값을 check_output에 연결하여 최종 출력값을 만든다. | 추출한 IP를 Line Notify를 통해 라인으로 받는다. | . 3. Crontab&#50640;&#49436; . PATH=/usr/bin:/usr/sbin:/sbin:/usr/local/bin # ifconfig, grep을 잘 실행시키기 위한 환경 지정 # ssh 접속용 사내 Wifi ipv4 전송용 # 매주 월요일 오전 10시에 전송 00 10 * * 1 /usr/bin/python3.9 /home/limyj0708/Code/ipv4_internal_alarm/ipv4_internal_alarm.py &gt;&gt; /home/limyj0708/Code/ipv4_internal_alarm/cron_log.log 2&gt;&amp;1 . 4. &#44208;&#44284; . 지정한 Line Notify 봇을 통해 IP가 잘 날아온다. | . Reference . Shell=True는 Shell Injection에 취약 | Popen 클래스 개괄 | Subprocess 모듈 사용법 |",
            "url": "https://limyj0708.github.io/fastpages/python/linux/2021/11/17/%EB%A6%AC%EB%88%85%EC%8A%A4-shell-%EB%AA%85%EB%A0%B9%EC%96%B4-Python-%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8%EC%97%90%EC%84%9C-%EC%8B%A4%ED%96%89-+-Crontab.html",
            "relUrl": "/python/linux/2021/11/17/%EB%A6%AC%EB%88%85%EC%8A%A4-shell-%EB%AA%85%EB%A0%B9%EC%96%B4-Python-%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8%EC%97%90%EC%84%9C-%EC%8B%A4%ED%96%89-+-Crontab.html",
            "date": " • Nov 17, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "Python 스크립트 Console 유저 입력 받기",
            "content": "Python 스크립트를 실행 시, Console 창에서 유저의 입력을 받으려면? | . text = input(&quot;아무거나 입력하세요 : &quot;) print(f&quot;메아리 : {text}&quot;) . 메아리 : 맛있는 거 먹고 싶다 . 입력되는 값은 기본적으로 string이다. | . text1 = input(&quot;아무거나 입력하세요1 : &quot;) text2 = input(&quot;아무거나 입력하세요2 : &quot;) print(f&quot;메아리 : {text1 + text2}&quot;) print(type(text1)) . 메아리 : 12 &lt;class &#39;str&#39;&gt; . 다른 자료형으로 쓰려면 형변환을 해야 함 | . int1 = int(input(&quot;아무거나 입력하세요1 : &quot;)) int2 = int(input(&quot;아무거나 입력하세요2 : &quot;)) print(f&quot;메아리 : {int1 + int2}&quot;) . 메아리 : 3 . 유저가 잘못된 값을 입력할 때를 대비한 예외처리 | . try: num = int(input(&#39;숫자를 입력하세요: &#39;)) print(&#39;입력하신 숫자는 : &#39;, num) except ValueError: print(&#39;숫자를 넣으라니까?&#39;) . 숫자를 넣으라니까? . 올바른 값을 입력할 때까지 작동하는 예외처리 루프 | . while True: try: num = int(input(&#39;숫자를 입력하세요: &#39;)) print(&#39;입력하신 숫자는 : &#39;, num) break except ValueError: print(&#39;숫자를 넣으라니까?&#39;) . 숫자를 넣으라니까? . 숫자를 넣으라니까? . 숫자를 넣으라니까? . 입력하신 숫자는 : 11 . 한 줄에 여러 값 입력받기 | . name, age, position = input(&quot;이름, 나이, 직급을 입력하세요.&quot;).split() # 입력값을 쪼갬, 입력값은 스페이스로 구분되어야 함 print(&quot;이름 :&quot;, name) print(&quot;나이 :&quot;, age) print(&quot;직급 :&quot;, position) . 이름 : 홍길돌 나이 : 35 직급 : 과장 . 리스트를 입력받는다면 | . entered_list = input(&quot;직원들의 나이를 입력하세요 : &quot;).split() print(&#39;직원들이 나이 리스트_문자열 : &#39;,entered_list) num_list = list(map(int,entered_list)) # map 함수로 리스트의 모든 원소에 대해 int 형변환 시행 print(&#39;직원들의 나이 리스트_숫자변환: &#39;,num_list) print(&#39;평균 나이:&#39;, sum(num_list)/len(num_list)) . 직원들이 나이 리스트_문자열 : [&#39;24&#39;, &#39;45&#39;, &#39;34&#39;, &#39;37&#39;, &#39;33&#39;, &#39;29&#39;] 직원들의 나이 리스트_숫자변환: [24, 45, 34, 37, 33, 29] 평균 나이: 33.666666666666664 . 여러 줄로 입력받기 | . total_input = [] print(&quot;직원들의 이름을 쓰세요 : &quot;) while True: name = input() if name: total_input.append(name) else: break # 아무것도 입력하지 않고 엔터를 누르면 if문에서 false로 처리되어 # break를 만나게 됨 print(&#39;입력된 직원들의 이름 목록 :&#39;) print(total_input) . 직원들의 이름을 쓰세요 : . 입력된 직원들의 이름 목록 : [&#39;홍길동&#39;, &#39;둘리&#39;, &#39;마이콜&#39;] .",
            "url": "https://limyj0708.github.io/fastpages/python/2021/11/08/Python_%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8_%EC%BD%98%EC%86%94_%EC%9C%A0%EC%A0%80_%EC%9E%85%EB%A0%A5_%EB%B0%9B%EA%B8%B0.html",
            "relUrl": "/python/2021/11/08/Python_%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8_%EC%BD%98%EC%86%94_%EC%9C%A0%EC%A0%80_%EC%9E%85%EB%A0%A5_%EB%B0%9B%EA%B8%B0.html",
            "date": " • Nov 8, 2021"
        }
        
    
  
    
        ,"post7": {
            "title": "Pandas CheatSheet",
            "content": "import pandas as pd import numpy as np from IPython.display import display_html . 1. Dataframe &#49373;&#49457; . 1-1. Dictionary&#50640;&#49436; Dataframe &#49373;&#49457; . data = {&#39;col_1&#39;: [3, 2, 1, 0], &#39;col_2&#39;: [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;]} pd.DataFrame.from_dict(data) # key가 컬럼, value로 들어간 리스트가 컬럼의 row 하나하나가 된다. . col_1 col_2 . 0 3 | a | . 1 2 | b | . 2 1 | c | . 3 0 | d | . dict_list = [ { &quot;id&quot; : 1001001, &quot;address&quot; : &quot;AABCC&quot;} ,{ &quot;id&quot; : 2101001, &quot;address&quot; : &quot;BBBDD&quot;} ,{ &quot;id&quot; : 3201001, &quot;address&quot; : &quot;백두산&quot;} ,{ &quot;id&quot; : 4301001, &quot;address&quot; : &quot;한라산&quot;} ,{ &quot;id&quot; : 5401001, &quot;address&quot; : &quot;몰디브&quot;} ] # 같은 key들을 가진 딕셔너리들이 담긴 리스트 pd.DataFrame.from_dict(dict_list) # 이렇게 넣어도, key들이 컬럼이 되어 데이터프레임이 만들어진다. # 실무적으로는 이 형태를 더 많이 쓰게 된다. . id address . 0 1001001 | AABCC | . 1 2101001 | BBBDD | . 2 3201001 | 백두산 | . 3 4301001 | 한라산 | . 4 5401001 | 몰디브 | . 1-2. Column&#47564; &#51316;&#51116;&#54616;&#45716; &#48712; Dataframe&#51012; &#47564;&#46308;&#44256;, &#45236;&#50857; &#52292;&#50892; &#45347;&#44592; . df = pd.DataFrame(columns=[&#39;A&#39;,&#39;B&#39;,&#39;BB&#39;,&#39;C&#39;,&#39;D&#39;]) # 컬럼들이 될 리스트를 columns parameter에 argument로 넘김 df . A B BB C D . df[&#39;A&#39;] = [1,3,1] df . A B BB C D . 0 1 | NaN | NaN | NaN | NaN | . 1 3 | NaN | NaN | NaN | NaN | . 2 1 | NaN | NaN | NaN | NaN | . df[&#39;B&#39;] = [4,4,6] df . A B BB C D . 0 1 | 4 | NaN | NaN | NaN | . 1 3 | 4 | NaN | NaN | NaN | . 2 1 | 6 | NaN | NaN | NaN | . df.loc[((df[&#39;A&#39;] == 1) &amp; (df[&#39;B&#39;] == 4)), &#39;C&#39;] = 444 df # 컬럼 값 조건을 걸고 값을 변경 . A B BB C D . 0 1 | 4 | NaN | 444 | NaN | . 1 3 | 4 | NaN | NaN | NaN | . 2 1 | 6 | NaN | NaN | NaN | . df.loc[(df[&#39;B&#39;] == 4), &#39;C&#39;] = 0 df # 컬럼 값 조건을 걸고 값을 변경 2 . A B BB C D . 0 1 | 4 | NaN | 0 | NaN | . 1 3 | 4 | NaN | 0 | NaN | . 2 1 | 6 | NaN | NaN | NaN | . sample_list = [1,2,3,4,5] # 해당 데이터프레임 가장 아래에 리스트를 row로 넣음 df.loc[len(df)] = sample_list # 이 방식은 좀 느린 편이며, 데이터프레임에 행을 추가해야 한다면 # 자료를 dictionary로 관리하다가 모든 데이터 추가가 다 끝나고 데이터프레임으로 변환하는 것이 빠름 df . A B BB C D . 0 1 | 4 | NaN | 0 | NaN | . 1 3 | 4 | NaN | 0 | NaN | . 2 1 | 6 | NaN | NaN | NaN | . 3 1 | 2 | 3 | 4 | 5 | . 2. Indexing, &#44050; &#48320;&#44221; &amp; &#52628;&#44032; . 2-1. loc : &#46972;&#48296; &#51064;&#45937;&#49905; . print(type(df.loc[0])) df.loc[0] # loc의 첫 번째 인자는 &#39;행 라벨&#39; 이다. # 그래서 0을 넣으면, index가 0인 행을 series로 반환하고 있다. . &lt;class &#39;pandas.core.series.Series&#39;&gt; . A 1 B 4 BB NaN C 0 D NaN Name: 0, dtype: object . print(type(df.loc[0, &#39;A&#39;])) df.loc[0, &#39;A&#39;] # 두 번째 인자는 컬럼명이다. . &lt;class &#39;numpy.int64&#39;&gt; . 1 . df.loc[[0,1,2,3], [&#39;A&#39;,&#39;B&#39;]] # 이런 식으로 접근하면, 다중 컬럼과 행을 데이터프레임으로 가져올 수 있다. . A B . 0 1 | 4 | . 1 3 | 4 | . 2 1 | 6 | . 3 1 | 2 | . df.loc[df.index[0:3], [&#39;A&#39;,&#39;B&#39;]] # df.index로도 접근 가능 . A B . 0 1 | 4 | . 1 3 | 4 | . 2 1 | 6 | . df.loc[df[&#39;B&#39;] == 4] # row에 값 조건을 걸 수도 있다. . A B BB C D . 0 1 | 4 | NaN | 0 | NaN | . 1 3 | 4 | NaN | 0 | NaN | . df.loc[df[&#39;B&#39;] == 4, df.columns.str.contains(&#39;B&#39;)] # 컬럼 이름에도 조건을 걸 수 있다. 위의 경우, 컬럼 이름에 B를 포함하는 컬럼만 가져옴. . B BB . 0 4 | NaN | . 1 4 | NaN | . df.loc[:,df.columns.str.contains(&#39;B&#39;)] # 행 조건 자리에 :를 넣으면, 행에 대해서는 전체를 다 가져오라는 뜻이다. . B BB . 0 4 | NaN | . 1 4 | NaN | . 2 6 | NaN | . 3 2 | 3 | . print(df.columns) # 컬럼명을 가져옴 print(df.columns.str) print(df.columns.str.contains(&#39;B&#39;)) # boolean indexing이 가능한 형태가 된다. print(type(df.columns.str.contains(&#39;B&#39;))) # 결과물은 false와 true가 들어간 ndarray print(df.columns.str.startswith(&#39;A&#39;)) # 이렇게 하면 A로 시작하는 컬럼을 가져올 수 있음 # 결론은, 다른 외부 함수를 사용해서 어쩄든 boolean 타입 값이 담긴 리스트를 만들면, loc에 넣어서 boolean indexing이 가능하다는 것. . Index([&#39;A&#39;, &#39;B&#39;, &#39;BB&#39;, &#39;C&#39;, &#39;D&#39;], dtype=&#39;object&#39;) &lt;pandas.core.strings.StringMethods object at 0x000001E1FEC0B250&gt; [False True True False False] &lt;class &#39;numpy.ndarray&#39;&gt; [ True False False False False] . df.loc[:,&#39;new&#39;] = 3 df # loc으로도 기존에 없던 새 컬럼을 추가할 수 있음 . A B BB C D new . 0 1 | 4 | NaN | 0 | NaN | 3 | . 1 3 | 4 | NaN | 0 | NaN | 3 | . 2 1 | 6 | NaN | NaN | NaN | 3 | . 3 1 | 2 | 3 | 4 | 5 | 3 | . df.loc[4] = [1] * len(df.columns) df.loc[99] = [1] * len(df.columns) df.loc[&#39;cool&#39;] = [22] * len(df.columns) # dataframe에 행을 추가함. index가 늘어난다. df . A B BB C D new . 0 1 | 4 | NaN | 0 | NaN | 3 | . 1 3 | 4 | NaN | 0 | NaN | 3 | . 2 1 | 6 | NaN | NaN | NaN | 3 | . 3 1 | 2 | 3 | 4 | 5 | 3 | . 4 1 | 1 | 1 | 1 | 1 | 1 | . 99 1 | 1 | 1 | 1 | 1 | 1 | . cool 22 | 22 | 22 | 22 | 22 | 22 | . 2-2. iloc : &#50948;&#52824; &#51064;&#45937;&#49905; . df.iloc[0:2,0:4] # 기본적 동작은 loc과 동일하나, 받는 인자가 라벨이 아니고 &#39;위치&#39;다. . A B BB C . 0 1 | 4 | NaN | 0 | . 1 3 | 4 | NaN | 0 | . df.iloc[4:7,0:4] # 위치를 받기 때문에, index는 99여도 5번째 줄로 인식됨 . A B BB C . 4 1 | 1 | 1 | 1 | . 99 1 | 1 | 1 | 1 | . cool 22 | 22 | 22 | 22 | . df.iloc[7] = [2] * len(df.columns) # IndexError: iloc cannot enlarge its target object # 위치를 인자로 받기 때문에, 새로운 컬럼, 행을 만든다거나 하는 행위는 불가능하다. . IndexError Traceback (most recent call last) &lt;ipython-input-23-83071db66eb6&gt; in &lt;module&gt; -&gt; 1 df.iloc[7] = [2] * len(df.columns) 2 # IndexError: iloc cannot enlarge its target object 3 # 위치를 인자로 받기 때문에, 새로운 컬럼, 행을 만든다거나 하는 행위는 불가능하다. c: users limyj0708 documents python lib site-packages pandas core indexing.py in __setitem__(self, key, value) 665 key = com.apply_if_callable(key, self.obj) 666 indexer = self._get_setitem_indexer(key) --&gt; 667 self._has_valid_setitem_indexer(key) 668 669 iloc = self if self.name == &#34;iloc&#34; else self.obj.iloc c: users limyj0708 documents python lib site-packages pandas core indexing.py in _has_valid_setitem_indexer(self, indexer) 1392 elif is_integer(i): 1393 if i &gt;= len(ax): -&gt; 1394 raise IndexError(&#34;iloc cannot enlarge its target object&#34;) 1395 elif isinstance(i, dict): 1396 raise IndexError(&#34;iloc cannot enlarge its target object&#34;) IndexError: iloc cannot enlarge its target object . 2-3. at : &#49828;&#52860;&#46972;&#44050; &#51217;&#44540; . df.at[1,&#39;A&#39;] # 한 번에 1개의 스칼라값에만 접근 가능 # 여러 개의 값에 접근하려고 범위를 지정하면, 에러를 출력한다. # 단일 값에 접근하는 목적이라면 loc보다 훨씬 빠름 . 3 . df.at[1,&#39;A&#39;] = 100 df # 값을 딱 하나만 바꾸고 싶다! 라고 하면 at을 활용해보자. . A B BB C D new . 0 1 | 4 | NaN | 0 | NaN | 3 | . 1 100 | 4 | NaN | 0 | NaN | 3 | . 2 1 | 6 | NaN | NaN | NaN | 3 | . 3 1 | 2 | 3 | 4 | 5 | 3 | . 4 1 | 1 | 1 | 1 | 1 | 1 | . 99 1 | 1 | 1 | 1 | 1 | 1 | . cool 22 | 22 | 22 | 22 | 22 | 22 | . df.at[99, &#39;new&#39;] # 그 이외에는 label base인 것이 loc과 똑같음 . 1 . 2-4. iat : iloc&#51032; &#49828;&#52860;&#46972; &#48260;&#51204; . df.iat[4,2] # iloc의 스칼라 버전. # 이외의 동작은 at과 같다. . 1 . df.iat[df.index.get_loc(&#39;cool&#39;),df.columns.get_loc(&#39;new&#39;)] # get_loc을 쓰면, 해당 인덱스와 컬럼의 위치를 반환받을 수 있음. # 그럼 인덱스와 컬럼의 이름으로도 iat, iloc을 이용 가능 . 22 . 2-5 map : Series&#51032; &#50896;&#49548; &#54616;&#45208;&#54616;&#45208;&#50640; &#54632;&#49688; &#51201;&#50857; . map함수는 DataFrame 타입이 아니라, 반드시 Series 타입에서만 사용해야 한다. | Series를 한마디로 정의하면 딱 이거다. 값(value) + 인덱스(index) = 시리즈 클래스(Series) | . | Series는 NumPy에서 제공하는 1차원 배열과 비슷하지만 각 데이터의 의미를 표시하는 인덱스(index)를 붙일 수 있다. 하지만 데이터 자체는 그냥 값(value)의 1차원 배열이다. | map함수는 Series의 이러한 값 하나하나에 접근하면서 해당 함수를 수행한다. | . import math as m # sqrt 함수 사용을 위해 부름 # http://www.leejungmin.org/post/2018/04/21/pandas_apply_and_map/ df[&quot;map_b&quot;] = df[&quot;B&quot;].map(lambda x : m.sqrt(x)) # B컬럼의 값 하나하나에 sqrt 함수를 적용한 결과를 map_b 컬럼으로 추가 df . A B BB C D new map_b . 0 1 | 4 | NaN | 0 | NaN | 3 | 2.000000 | . 1 100 | 4 | NaN | 0 | NaN | 3 | 2.000000 | . 2 1 | 6 | NaN | NaN | NaN | 3 | 2.449490 | . 3 1 | 2 | 3 | 4 | 5 | 3 | 1.414214 | . 4 1 | 1 | 1 | 1 | 1 | 1 | 1.000000 | . 99 1 | 1 | 1 | 1 | 1 | 1 | 1.000000 | . cool 22 | 22 | 22 | 22 | 22 | 22 | 4.690416 | . 2-6. apply : &#52964;&#49828;&#53568; &#54632;&#49688;&#50640; &#48373;&#49688; &#44060;&#51032; &#52972;&#47100;&#51060; &#54596;&#50836;&#54616;&#45796;&#47732; . 커스텀 함수를 사용하기 위해 DataFrame에서 복수 개의 컬럼이 필요하다면, apply 함수를 사용해야 한다. | . import math as m # sqrt 함수 사용을 위해 부름 # 두 컬럼의 제곱근의 값을 각각 곱하는 함수 def sqrt_multi(x,y): return m.sqrt(x) * m.sqrt(y) . df.loc[:,&#39;new&#39;] = df.apply(lambda x : sqrt_multi(x[&#39;A&#39;], x[&#39;B&#39;]), axis=1) # axis=1 이면 각 열의 원소에 대해 연산 수행 df . A B BB C D new map_b . 0 1 | 4 | NaN | 0 | NaN | 2.000000 | 2.000000 | . 1 100 | 4 | NaN | 0 | NaN | 20.000000 | 2.000000 | . 2 1 | 6 | NaN | NaN | NaN | 2.449490 | 2.449490 | . 3 1 | 2 | 3 | 4 | 5 | 1.414214 | 1.414214 | . 4 1 | 1 | 1 | 1 | 1 | 1.000000 | 1.000000 | . 99 1 | 1 | 1 | 1 | 1 | 1.000000 | 1.000000 | . cool 22 | 22 | 22 | 22 | 22 | 22.000000 | 4.690416 | . df[&quot;apply_bb_d&quot;] = df.apply(lambda x : sqrt_multi(x[&#39;BB&#39;], x[&#39;B&#39;]), axis=1) # axis=1 이면 각 열의 원소에 대해 연산 수행 df # NaN과의 연산은 NaN이 됨을 참고하자. . A B BB C D new map_b apply_bb_d . 0 1 | 4 | NaN | 0 | NaN | 2.000000 | 2.000000 | NaN | . 1 100 | 4 | NaN | 0 | NaN | 20.000000 | 2.000000 | NaN | . 2 1 | 6 | NaN | NaN | NaN | 2.449490 | 2.449490 | NaN | . 3 1 | 2 | 3 | 4 | 5 | 1.414214 | 1.414214 | 2.44949 | . 4 1 | 1 | 1 | 1 | 1 | 1.000000 | 1.000000 | 1.00000 | . 99 1 | 1 | 1 | 1 | 1 | 1.000000 | 1.000000 | 1.00000 | . cool 22 | 22 | 22 | 22 | 22 | 22.000000 | 4.690416 | 22.00000 | . 2-7. index, columns&#47196; index&#50752; &#52972;&#47100;&#47749; &#51649;&#51217; &#51648;&#51221; . print(df.columns) print(type(df.columns)) print(df.index) print(type(df.index)) print(df.columns[2]) # 위치값으로 개별 요소에 접근 가능 print(df.index[6]) . Index([&#39;A&#39;, &#39;B&#39;, &#39;BB&#39;, &#39;C&#39;, &#39;D&#39;, &#39;new&#39;, &#39;map_b&#39;, &#39;apply_bb_d&#39;], dtype=&#39;object&#39;) &lt;class &#39;pandas.core.indexes.base.Index&#39;&gt; Index([0, 1, 2, 3, 4, 99, &#39;cool&#39;], dtype=&#39;object&#39;) &lt;class &#39;pandas.core.indexes.base.Index&#39;&gt; BB cool . df.columns = [&#39;가&#39;, &#39;나&#39;, &#39;다&#39;, &#39;라&#39;, &#39;마&#39;, &#39;바&#39;, &#39;사&#39;, &#39;아&#39;] # df.columns에 직접 컬럼명 리스트를 할당하여 컬럼명 변경 가능 # 기존 컬럼 수와 같은 길이의 리스트를 넣지 않으면 오류가 발생함 print(df.columns) print(type(df.columns)) . Index([&#39;가&#39;, &#39;나&#39;, &#39;다&#39;, &#39;라&#39;, &#39;마&#39;, &#39;바&#39;, &#39;사&#39;, &#39;아&#39;], dtype=&#39;object&#39;) &lt;class &#39;pandas.core.indexes.base.Index&#39;&gt; . df.index = [1,2,3,4,5,6,7] # df.columns에 직접 컬럼명 리스트를 할당하여 컬럼명 변경 가능 print(df.index) print(type(df.index)) . Int64Index([1, 2, 3, 4, 5, 6, 7], dtype=&#39;int64&#39;) &lt;class &#39;pandas.core.indexes.numeric.Int64Index&#39;&gt; . 2-8. set_index&#47196; index &#49444;&#51221; . DataFrame.set_index(keys, drop=True, append=False, inplace=False) . keys에는 index로 할당하고자 하는 열의 레이블을 입력한다. multi-index를 하고 싶으면, [&#39;가&#39;, &#39;나&#39;] 이렇게 열 레이블 배열을 입력한다. | . | drop : index로 할당한 열을 삭제할까요? | append : 기존에 존재하던 index를 삭제할까요? | inplace : 원본 데이터프레임을 변경할까요? | . df . 가 나 다 라 마 바 사 아 . 1 1 | 4 | NaN | 0 | NaN | 2.000000 | 2.000000 | NaN | . 2 100 | 4 | NaN | 0 | NaN | 20.000000 | 2.000000 | NaN | . 3 1 | 6 | NaN | NaN | NaN | 2.449490 | 2.449490 | NaN | . 4 1 | 2 | 3 | 4 | 5 | 1.414214 | 1.414214 | 2.44949 | . 5 1 | 1 | 1 | 1 | 1 | 1.000000 | 1.000000 | 1.00000 | . 6 1 | 1 | 1 | 1 | 1 | 1.000000 | 1.000000 | 1.00000 | . 7 22 | 22 | 22 | 22 | 22 | 22.000000 | 4.690416 | 22.00000 | . df.set_index(&#39;가&#39;) # 기본값 . 나 다 라 마 바 사 아 . 가 . 1 4 | NaN | 0 | NaN | 2.000000 | 2.000000 | NaN | . 100 4 | NaN | 0 | NaN | 20.000000 | 2.000000 | NaN | . 1 6 | NaN | NaN | NaN | 2.449490 | 2.449490 | NaN | . 1 2 | 3 | 4 | 5 | 1.414214 | 1.414214 | 2.44949 | . 1 1 | 1 | 1 | 1 | 1.000000 | 1.000000 | 1.00000 | . 1 1 | 1 | 1 | 1 | 1.000000 | 1.000000 | 1.00000 | . 22 22 | 22 | 22 | 22 | 22.000000 | 4.690416 | 22.00000 | . df.set_index(&#39;가&#39;, drop=False) # index로 선택된 열 삭제 안 함 . 가 나 다 라 마 바 사 아 . 가 . 1 1 | 4 | NaN | 0 | NaN | 2.000000 | 2.000000 | NaN | . 100 100 | 4 | NaN | 0 | NaN | 20.000000 | 2.000000 | NaN | . 1 1 | 6 | NaN | NaN | NaN | 2.449490 | 2.449490 | NaN | . 1 1 | 2 | 3 | 4 | 5 | 1.414214 | 1.414214 | 2.44949 | . 1 1 | 1 | 1 | 1 | 1 | 1.000000 | 1.000000 | 1.00000 | . 1 1 | 1 | 1 | 1 | 1 | 1.000000 | 1.000000 | 1.00000 | . 22 22 | 22 | 22 | 22 | 22 | 22.000000 | 4.690416 | 22.00000 | . df.set_index(&#39;가&#39;, append=True) # 기존 index 삭제 안 함 . 나 다 라 마 바 사 아 . 가 . 1 1 4 | NaN | 0 | NaN | 2.000000 | 2.000000 | NaN | . 2 100 4 | NaN | 0 | NaN | 20.000000 | 2.000000 | NaN | . 3 1 6 | NaN | NaN | NaN | 2.449490 | 2.449490 | NaN | . 4 1 2 | 3 | 4 | 5 | 1.414214 | 1.414214 | 2.44949 | . 5 1 1 | 1 | 1 | 1 | 1.000000 | 1.000000 | 1.00000 | . 6 1 1 | 1 | 1 | 1 | 1.000000 | 1.000000 | 1.00000 | . 7 22 22 | 22 | 22 | 22 | 22.000000 | 4.690416 | 22.00000 | . df.set_index([&#39;가&#39;,&#39;나&#39;]) # 동시에 여러 열을 index로 설정하기 . 다 라 마 바 사 아 . 가 나 . 1 4 NaN | 0 | NaN | 2.000000 | 2.000000 | NaN | . 100 4 NaN | 0 | NaN | 20.000000 | 2.000000 | NaN | . 1 6 NaN | NaN | NaN | 2.449490 | 2.449490 | NaN | . 2 3 | 4 | 5 | 1.414214 | 1.414214 | 2.44949 | . 1 1 | 1 | 1 | 1.000000 | 1.000000 | 1.00000 | . 1 1 | 1 | 1 | 1.000000 | 1.000000 | 1.00000 | . 22 22 22 | 22 | 22 | 22.000000 | 4.690416 | 22.00000 | . 2-9. reset_index&#47196; index &#52488;&#44592;&#54868; . DataFrame.reset_index(drop=False, inplace=False) . 기존에 있던 index 대신에, 0부터 시작하여 1씩 늘어나는 정수 index를 추가한다. | drop : 기존에 index였던 열을 삭제할까요? | inplace : 원본 데이터프레임을 변경할까요? | . df.reset_index() . index 가 나 다 라 마 바 사 아 . 0 1 | 1 | 4 | NaN | 0 | NaN | 2.000000 | 2.000000 | NaN | . 1 2 | 100 | 4 | NaN | 0 | NaN | 20.000000 | 2.000000 | NaN | . 2 3 | 1 | 6 | NaN | NaN | NaN | 2.449490 | 2.449490 | NaN | . 3 4 | 1 | 2 | 3 | 4 | 5 | 1.414214 | 1.414214 | 2.44949 | . 4 5 | 1 | 1 | 1 | 1 | 1 | 1.000000 | 1.000000 | 1.00000 | . 5 6 | 1 | 1 | 1 | 1 | 1 | 1.000000 | 1.000000 | 1.00000 | . 6 7 | 22 | 22 | 22 | 22 | 22 | 22.000000 | 4.690416 | 22.00000 | . df.reset_index(drop=True) . 가 나 다 라 마 바 사 아 . 0 1 | 4 | NaN | 0 | NaN | 2.000000 | 2.000000 | NaN | . 1 100 | 4 | NaN | 0 | NaN | 20.000000 | 2.000000 | NaN | . 2 1 | 6 | NaN | NaN | NaN | 2.449490 | 2.449490 | NaN | . 3 1 | 2 | 3 | 4 | 5 | 1.414214 | 1.414214 | 2.44949 | . 4 1 | 1 | 1 | 1 | 1 | 1.000000 | 1.000000 | 1.00000 | . 5 1 | 1 | 1 | 1 | 1 | 1.000000 | 1.000000 | 1.00000 | . 6 22 | 22 | 22 | 22 | 22 | 22.000000 | 4.690416 | 22.00000 | . 3. &#44050; &#49325;&#51228;, &#45824;&#52404; . 특정 조건의 값을 삭제하고 싶은 경우에는, 해당 조건의 반대 조건을 걸어서 반환 결과를 사용하는 식으로 처리한다. | . 3-1. drop : &#50896;&#54616;&#45716; &#54665;, &#50676; &#51648;&#50864;&#44592; . DataFrame.drop(labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors=&#39;raise&#39;) . 특정 레이블의 행이나 열을 제거한다. | labels : 제거할 index, 레이블 하나 혹은 리스트 (list-like) | axis : 0이면 행, 1이면 컬럼 대상 | index : labels, axis=0 대신 사용가능 | columns : labels, axis=1 대신 사용가능 | level : MultiIndex일 경우, 어떤 레벨을 제거할 것인지 | inplace : 원본 변경 할 건가요? | errors : &#39;ignore&#39;로 세팅하면, 에러 출력 안 하고 존재하는 레이블만 제거한다. | . df . 가 나 다 라 마 바 사 아 . 1 1 | 4 | NaN | 0 | NaN | 2.000000 | 2.000000 | NaN | . 2 100 | 4 | NaN | 0 | NaN | 20.000000 | 2.000000 | NaN | . 3 1 | 6 | NaN | NaN | NaN | 2.449490 | 2.449490 | NaN | . 4 1 | 2 | 3 | 4 | 5 | 1.414214 | 1.414214 | 2.44949 | . 5 1 | 1 | 1 | 1 | 1 | 1.000000 | 1.000000 | 1.00000 | . 6 1 | 1 | 1 | 1 | 1 | 1.000000 | 1.000000 | 1.00000 | . 7 22 | 22 | 22 | 22 | 22 | 22.000000 | 4.690416 | 22.00000 | . df.drop(labels=[&#39;가&#39;,&#39;아&#39;], axis=1) . 나 다 라 마 바 사 . 1 4 | NaN | 0 | NaN | 2.000000 | 2.000000 | . 2 4 | NaN | 0 | NaN | 20.000000 | 2.000000 | . 3 6 | NaN | NaN | NaN | 2.449490 | 2.449490 | . 4 2 | 3 | 4 | 5 | 1.414214 | 1.414214 | . 5 1 | 1 | 1 | 1 | 1.000000 | 1.000000 | . 6 1 | 1 | 1 | 1 | 1.000000 | 1.000000 | . 7 22 | 22 | 22 | 22 | 22.000000 | 4.690416 | . df.drop(labels=[1,7], axis=0) . 가 나 다 라 마 바 사 아 . 2 100 | 4 | NaN | 0 | NaN | 20.000000 | 2.000000 | NaN | . 3 1 | 6 | NaN | NaN | NaN | 2.449490 | 2.449490 | NaN | . 4 1 | 2 | 3 | 4 | 5 | 1.414214 | 1.414214 | 2.44949 | . 5 1 | 1 | 1 | 1 | 1 | 1.000000 | 1.000000 | 1.00000 | . 6 1 | 1 | 1 | 1 | 1 | 1.000000 | 1.000000 | 1.00000 | . df.drop(columns=[&#39;가&#39;,&#39;아&#39;]) # df.drop(labels=[&#39;가&#39;,&#39;아&#39;], axis=1)와 같은 결과 . 나 다 라 마 바 사 . 1 4 | NaN | 0 | NaN | 2.000000 | 2.000000 | . 2 4 | NaN | 0 | NaN | 20.000000 | 2.000000 | . 3 6 | NaN | NaN | NaN | 2.449490 | 2.449490 | . 4 2 | 3 | 4 | 5 | 1.414214 | 1.414214 | . 5 1 | 1 | 1 | 1 | 1.000000 | 1.000000 | . 6 1 | 1 | 1 | 1 | 1.000000 | 1.000000 | . 7 22 | 22 | 22 | 22 | 22.000000 | 4.690416 | . 3-2. Na &#45824;&#51025; . 3-2-1. isna : NaN&#51064;&#51648; &#44033; &#44050;&#50640; &#45824;&#54644; &#54869;&#51064; . NaN인지 각 값에 대해 확인하여 boolean으로 표현 | isnull() 도 완전히 같은 기능을 한다. | 왜 같은 기능을 하는 함수가 두 개나 있는지는 아래 링크를 참조 https://datascience.stackexchange.com/questions/37878/difference-between-isna-and-isnull-in-pandasThis is because pandas&#39; DataFrames are based on R&#39;s DataFrames. In R na and null are two separate things. Read this post for more information. However, in python, pandas is built on top of numpy, which has neither na nor null values. Instead numpy has NaN values (which stands for &quot;Not a Number&quot;). Consequently, pandas also uses NaN values. . | . | . df.isna() # 특정 컬럼, 행에 대해서도 사용 가능 . 가 나 다 라 마 바 사 아 . 1 False | False | True | False | True | False | False | True | . 2 False | False | True | False | True | False | False | True | . 3 False | False | True | True | True | False | False | True | . 4 False | False | False | False | False | False | False | False | . 5 False | False | False | False | False | False | False | False | . 6 False | False | False | False | False | False | False | False | . 7 False | False | False | False | False | False | False | False | . 3-2-2. dropna : NA &#46300;&#46989; . DataFrame.dropna(axis=0, how=&#39;any&#39;, thresh=None, subset=None, inplace=False) . axis 0 혹은 &#39;index&#39; : missing value가 있는 행을 드랍 | 1 혹은 &#39;columns&#39; : missing value가 있는 열을 드랍 | . | how any : missing value가 하나라도 있으면 드랍 | all : 전체 값이 다 missing value여야 드랍 | . | thresh : 문턱값. 정수를 입력 시, 정상값이 해당 정수 갯수만큼은 있어야 제거 안 함 | subset : list-like 오브젝트를 넣으면, 해당 index나 컬럼에서만 missing value 체크 | inplace : 원본 변경 할 건가요? | . df . 가 나 다 라 마 바 사 아 . 1 1 | 4 | NaN | 0 | NaN | 2.000000 | 2.000000 | NaN | . 2 100 | 4 | NaN | 0 | NaN | 20.000000 | 2.000000 | NaN | . 3 1 | 6 | NaN | NaN | NaN | 2.449490 | 2.449490 | NaN | . 4 1 | 2 | 3 | 4 | 5 | 1.414214 | 1.414214 | 2.44949 | . 5 1 | 1 | 1 | 1 | 1 | 1.000000 | 1.000000 | 1.00000 | . 6 1 | 1 | 1 | 1 | 1 | 1.000000 | 1.000000 | 1.00000 | . 7 22 | 22 | 22 | 22 | 22 | 22.000000 | 4.690416 | 22.00000 | . df.dropna() # 기본적으로 행 드랍 . 가 나 다 라 마 바 사 아 . 4 1 | 2 | 3 | 4 | 5 | 1.414214 | 1.414214 | 2.44949 | . 5 1 | 1 | 1 | 1 | 1 | 1.000000 | 1.000000 | 1.00000 | . 6 1 | 1 | 1 | 1 | 1 | 1.000000 | 1.000000 | 1.00000 | . 7 22 | 22 | 22 | 22 | 22 | 22.000000 | 4.690416 | 22.00000 | . df.dropna(axis=1) # 열 드랍 . 가 나 바 사 . 1 1 | 4 | 2.000000 | 2.000000 | . 2 100 | 4 | 20.000000 | 2.000000 | . 3 1 | 6 | 2.449490 | 2.449490 | . 4 1 | 2 | 1.414214 | 1.414214 | . 5 1 | 1 | 1.000000 | 1.000000 | . 6 1 | 1 | 1.000000 | 1.000000 | . 7 22 | 22 | 22.000000 | 4.690416 | . df.dropna(thresh=5) # index 3인 행은 정상값이 4개였음 . 가 나 다 라 마 바 사 아 . 1 1 | 4 | NaN | 0 | NaN | 2.000000 | 2.000000 | NaN | . 2 100 | 4 | NaN | 0 | NaN | 20.000000 | 2.000000 | NaN | . 4 1 | 2 | 3 | 4 | 5 | 1.414214 | 1.414214 | 2.44949 | . 5 1 | 1 | 1 | 1 | 1 | 1.000000 | 1.000000 | 1.00000 | . 6 1 | 1 | 1 | 1 | 1 | 1.000000 | 1.000000 | 1.00000 | . 7 22 | 22 | 22 | 22 | 22 | 22.000000 | 4.690416 | 22.00000 | . df.dropna(axis=0, subset=[&#39;라&#39;]) # &#39;라&#39;열만 검사해서 NaN이 있는 행을 제거함 . 가 나 다 라 마 바 사 아 . 1 1 | 4 | NaN | 0 | NaN | 2.000000 | 2.000000 | NaN | . 2 100 | 4 | NaN | 0 | NaN | 20.000000 | 2.000000 | NaN | . 4 1 | 2 | 3 | 4 | 5 | 1.414214 | 1.414214 | 2.44949 | . 5 1 | 1 | 1 | 1 | 1 | 1.000000 | 1.000000 | 1.00000 | . 6 1 | 1 | 1 | 1 | 1 | 1.000000 | 1.000000 | 1.00000 | . 7 22 | 22 | 22 | 22 | 22 | 22.000000 | 4.690416 | 22.00000 | . 3-2-3. fillna : NaN &#45936;&#51060;&#53552; &#45824;&#52404;&#54616;&#44592; . DataFrame.fillna(value=None, method=None, axis=None, inplace=False, limit=None, downcast=None) . value : NaN을 무엇으로 채울 것인가? scalar : 0, 1 따위의 값을 넣음 | dict : {&quot;A&quot;: 0, &quot;B&quot;: 1, &quot;C&quot;: 2, &quot;D&quot;: 3} 컬럼 A의 NaN은 0으로, 컬럼 B의 NaN은 1로, 컬럼 C의 NaN은 2로, 컬럼 D의 NaN은 3으로 대체 | . | dataframe : 대체 대상 dataframe와 같은 크기의 dataframe을 준비한 후, value에 dataframe을 넣으면 NaN 값만 넣은 dataframe의 값으로 대체된다. 컬럼명이나 인덱스는 원본 dataframe의 것이 유지된다. | . | method : 어떤 방법으로 채울까? (value와 같이 사용할 수 없음) backfill, bfill : NaN의 다음 값으로 NaN 채우기. | ffill, pad : NaN의 직전 값으로 NaN 채우기. | . | axis 0 혹은 &#39;index&#39; | 1 혹은 &#39;columns&#39; | . | inplace : 원본 변경 할 건가요? | limit : 위에서부터 NaN 몇 개만 바꿀래? 기본값 None이면 모든 NaN을 바꾸는 것. | . df = pd.DataFrame([[np.nan, 2, np.nan, 0], [3, 4, np.nan, 1], [np.nan, np.nan, np.nan, 5], [np.nan, 3, np.nan, 4]], columns=list(&quot;ABCD&quot;)) df . A B C D . 0 NaN | 2.0 | NaN | 0 | . 1 3.0 | 4.0 | NaN | 1 | . 2 NaN | NaN | NaN | 5 | . 3 NaN | 3.0 | NaN | 4 | . df.fillna(value=0) # 0으로 NaN 채우기 . A B C D . 0 0.0 | 2.0 | 0.0 | 0 | . 1 3.0 | 4.0 | 0.0 | 1 | . 2 0.0 | 0.0 | 0.0 | 5 | . 3 0.0 | 3.0 | 0.0 | 4 | . df.fillna(method=&#39;ffill&#39;) # NaN의 직전 값으로 NaN 채우기. &#39;pad&#39;를 써도 마찬가지 . A B C D . 0 NaN | 2.0 | NaN | 0 | . 1 3.0 | 4.0 | NaN | 1 | . 2 3.0 | 4.0 | NaN | 5 | . 3 3.0 | 3.0 | NaN | 4 | . df.fillna(method=&#39;bfill&#39;) # NaN의 다음 값으로 NaN 채우기. &#39;backfill&#39;을 써도 마찬가지 . A B C D . 0 3.0 | 2.0 | NaN | 0 | . 1 3.0 | 4.0 | NaN | 1 | . 2 NaN | 3.0 | NaN | 5 | . 3 NaN | 3.0 | NaN | 4 | . values = {&quot;A&quot;: 0, &quot;B&quot;: 1, &quot;C&quot;: 2, &quot;D&quot;: 3} df.fillna(value=values) # values에 dictionary를 넣어서 컬럼마다 NaN을 다른 값으로 대체 . A B C D . 0 0.0 | 2.0 | 2.0 | 0 | . 1 3.0 | 4.0 | 2.0 | 1 | . 2 0.0 | 1.0 | 2.0 | 5 | . 3 0.0 | 3.0 | 2.0 | 4 | . df.fillna(value=values, limit=1) # limit=1이어서, 최초의 NaN 하나만 대체 . A B C D . 0 0.0 | 2.0 | 2.0 | 0 | . 1 3.0 | 4.0 | NaN | 1 | . 2 NaN | 1.0 | NaN | 5 | . 3 NaN | 3.0 | NaN | 4 | . df2 = pd.DataFrame(np.zeros((4, 4)), columns=list(&quot;ABCE&quot;)) df2 # 4 by 4 영행렬을 만들어 보자 . A B C E . 0 0.0 | 0.0 | 0.0 | 0.0 | . 1 0.0 | 0.0 | 0.0 | 0.0 | . 2 0.0 | 0.0 | 0.0 | 0.0 | . 3 0.0 | 0.0 | 0.0 | 0.0 | . df.fillna(df2) #원본 df의 컬럼이 유지됨 . A B C D . 0 0.0 | 2.0 | 0.0 | 0 | . 1 3.0 | 4.0 | 0.0 | 1 | . 2 0.0 | 0.0 | 0.0 | 5 | . 3 0.0 | 3.0 | 0.0 | 4 | . df.loc[:,&#39;A&#39;].fillna(df.loc[:,&#39;A&#39;].mean()) # A열의 NaN 값을 A열의 평균으로 채움 . 0 3.0 1 3.0 2 3.0 3 3.0 Name: A, dtype: float64 . 3-3. drop_duplicates : &#51473;&#48373;&#44050; &#51228;&#44144; . DataFrame.drop_duplicates(subset=None, keep=&#39;first&#39;, inplace=False, ignore_index=False) . subset : 컬럼 라벨, 혹은 컬럼 라벨 리스트 넣은 특정 컬럼만 중복값을 체크함. 기본으로는 전체 컬럼의 값이 다 같아야 제거 | . | keep first : 첫 번째 등장한 것을 제외하면 다 제거 | last : 마지막에 등장한 것을 제외하면 다 제거 | False : 몽땅 다 제거 | . | inplace : 원본 변경 할 건가요? | ignore_index : True 값을 넣으면, 결과값의 인덱스를 0, 1, ... n-1로 라벨링함 | . df = pd.DataFrame({ &#39;brand&#39;: [&#39;Yum Yum&#39;, &#39;Yum Yum&#39;, &#39;Indomie&#39;, &#39;Indomie&#39;, &#39;Indomie&#39;], &#39;style&#39;: [&#39;cup&#39;, &#39;cup&#39;, &#39;cup&#39;, &#39;pack&#39;, &#39;pack&#39;], &#39;rating&#39;: [4, 4, 3.5, 15, 5] }) df . brand style rating . 0 Yum Yum | cup | 4.0 | . 1 Yum Yum | cup | 4.0 | . 2 Indomie | cup | 3.5 | . 3 Indomie | pack | 15.0 | . 4 Indomie | pack | 5.0 | . df.drop_duplicates() # 모든 열의 값이 다 같으면 제거 . brand style rating . 0 Yum Yum | cup | 4.0 | . 2 Indomie | cup | 3.5 | . 3 Indomie | pack | 15.0 | . 4 Indomie | pack | 5.0 | . df.drop_duplicates(subset=[&#39;brand&#39;]) # brand 컬럼 하나에서만 값이 같아도 제거 . brand style rating . 0 Yum Yum | cup | 4.0 | . 2 Indomie | cup | 3.5 | . df.drop_duplicates(subset=[&#39;brand&#39;, &#39;style&#39;], keep=&#39;last&#39;) # brand, style 모두 같으면, 마지막 값만 남김 . brand style rating . 1 Yum Yum | cup | 4.0 | . 2 Indomie | cup | 3.5 | . 4 Indomie | pack | 5.0 | . 4. Dataframe &#44208;&#54633; . 4-1. &#50948;&#50500;&#47000;&#47196; &#48537;&#51060;&#45716; &#45800;&#49692; &#44208;&#54633;&#51032; &#44221;&#50864;, &#50612;&#46500; &#48169;&#49885;&#51060; &#44032;&#51109; &#48736;&#47480;&#44032;? . 결론부터 말하자면 데이터를 Dictionary의 리스트로 관리하다가 마지막에 Dataframe으로 만드는 것이 가장 빠르다. . https://stackoverflow.com/questions/57000903/what-is-the-fastest-and-most-efficient-way-to-append-rows-to-a-dataframe . start_time = time.time() dictinary_list = [] for i in range(0, end_value, 1): dictionary_data = {k: random.random() for k in range(30)} dictionary_list.append(dictionary_data) df_final = pd.DataFrame.from_dict(dictionary_list) end_time = time.time() print(&#39;Execution time = %.6f seconds&#39; % (end_time-start_time)) . . | 그럼 리스트 합치는 건 뭐가 제일 빠르지? https://www.realpythonproject.com/day15-the-fastest-way-to-combine-lists-in-python/append() is the fastest but it doesn’t combine the elements of both the lists. The + operator seems to be the ideal option. However, this has been done on a comparatively smaller dataset and results may vary when you try it on your own. . | . | . | 인생은 항상 원하는대로 흘러가지 않기에, 다른 방법도 알아보자. | . 4-1-1. concat . pandas.concat(objs, axis=0, join=&#39;outer&#39;, ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, sort=False, copy=True) . s1 = pd.Series([&#39;a&#39;, &#39;b&#39;]) s2 = pd.Series([&#39;c&#39;, &#39;d&#39;]) pd.concat([s1, s2]) # Series 두 개 합치기 . 0 a 1 b 0 c 1 d dtype: object . pd.concat([s1, s2], ignore_index=True) # 합치면서 index 새로 만들어줌 . 0 a 1 b 2 c 3 d dtype: object . s3 = pd.concat([s1, s2], keys=[&#39;s1&#39;, &#39;s2&#39;]) # 최외각 레벨에 새로운 index를 만들어줌 print(s3) print(s3[&#39;s1&#39;]) print(s3[&#39;s2&#39;][0]) # 이렇게 조회가능 . s1 0 a 1 b s2 0 c 1 d dtype: object 0 a 1 b dtype: object c . s3 = pd.concat([s1, s2], keys=[&#39;s1&#39;, &#39;s2&#39;], names=[&#39;Series name&#39;, &#39;Row ID&#39;]) # index에 이름 붙이기 print(s3) print(s3.index) print(s3.index.names) . Series name Row ID s1 0 a 1 b s2 0 c 1 d dtype: object MultiIndex([(&#39;s1&#39;, 0), (&#39;s1&#39;, 1), (&#39;s2&#39;, 0), (&#39;s2&#39;, 1)], names=[&#39;Series name&#39;, &#39;Row ID&#39;]) [&#39;Series name&#39;, &#39;Row ID&#39;] . df1 = pd.DataFrame([[&#39;a&#39;, 1], [&#39;b&#39;, 2]], columns=[&#39;letter&#39;, &#39;number&#39;]) print(df1) df2 = pd.DataFrame([[&#39;c&#39;, 3], [&#39;d&#39;, 4]], columns=[&#39;letter&#39;, &#39;number&#39;]) print(df2) pd.concat([df1, df2]) # Dataframe 합치기 . letter number 0 a 1 1 b 2 letter number 0 c 3 1 d 4 . letter number . 0 a | 1 | . 1 b | 2 | . 0 c | 3 | . 1 d | 4 | . df3 = pd.DataFrame([[&#39;c&#39;, 3, &#39;cat&#39;], [&#39;d&#39;, 4, &#39;dog&#39;]], columns=[&#39;letter&#39;, &#39;number&#39;, &#39;animal&#39;]) print(df3) pd.concat([df1, df3], sort=False) # 한 쪽에 없는 컬럼의 값은 NaN으로 삽입됨 . letter number animal 0 c 3 cat 1 d 4 dog . letter number animal . 0 a | 1 | NaN | . 1 b | 2 | NaN | . 0 c | 3 | cat | . 1 d | 4 | dog | . pd.concat([df1, df3], join=&quot;inner&quot;) # join=&quot;inner&quot;로 하면 양쪽에 다 있는 컬럼만 합쳐서 반환함 . letter number . 0 a | 1 | . 1 b | 2 | . 0 c | 3 | . 1 d | 4 | . df4 = pd.DataFrame([[&#39;bird&#39;, &#39;polly&#39;], [&#39;monkey&#39;, &#39;george&#39;]], columns=[&#39;animal&#39;, &#39;name&#39;]) pd.concat([df1, df4], axis=1) # axis=1이면 컬럼을 붙임 . letter number animal name . 0 a | 1 | bird | polly | . 1 b | 2 | monkey | george | . df4 = pd.DataFrame([[&#39;bird&#39;, &#39;polly&#39;], [&#39;monkey&#39;, &#39;george&#39;], [&#39;dog&#39;, &#39;sam&#39;]], columns=[&#39;animal&#39;, &#39;name&#39;]) pd.concat([df1, df4], axis=1) # axis=1이면 컬럼을 붙임 # 행의 수가 다르면, 행이 적은 쪽에 NaN이 삽입된 행이 추가됨 . letter number animal name . 0 a | 1.0 | bird | polly | . 1 b | 2.0 | monkey | george | . 2 NaN | NaN | dog | sam | . df5 = pd.DataFrame([1], index=[&#39;a&#39;]) df6 = pd.DataFrame([2], index=[&#39;a&#39;]) pd.concat([df5, df6], verify_integrity=True) # verify_integrity=True를 하면, index가 같은 것을 허용하지 않음. . ValueError Traceback (most recent call last) &lt;ipython-input-149-5c78fd186f55&gt; in &lt;module&gt; 1 df5 = pd.DataFrame([1], index=[&#39;a&#39;]) 2 df6 = pd.DataFrame([2], index=[&#39;a&#39;]) -&gt; 3 pd.concat([df5, df6], verify_integrity=True) c: users limyj0708 documents python lib site-packages pandas core reshape concat.py in concat(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy) 272 ValueError: Indexes have overlapping values: [&#39;a&#39;] 273 &#34;&#34;&#34; --&gt; 274 op = _Concatenator( 275 objs, 276 axis=axis, c: users limyj0708 documents python lib site-packages pandas core reshape concat.py in __init__(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort) 452 self.copy = copy 453 --&gt; 454 self.new_axes = self._get_new_axes() 455 456 def get_result(self): c: users limyj0708 documents python lib site-packages pandas core reshape concat.py in _get_new_axes(self) 517 def _get_new_axes(self) -&gt; List[Index]: 518 ndim = self._get_result_dim() --&gt; 519 return [ 520 self._get_concat_axis() if i == self.bm_axis else self._get_comb_axis(i) 521 for i in range(ndim) c: users limyj0708 documents python lib site-packages pandas core reshape concat.py in &lt;listcomp&gt;(.0) 518 ndim = self._get_result_dim() 519 return [ --&gt; 520 self._get_concat_axis() if i == self.bm_axis else self._get_comb_axis(i) 521 for i in range(ndim) 522 ] c: users limyj0708 documents python lib site-packages pandas core reshape concat.py in _get_concat_axis(self) 578 ) 579 --&gt; 580 self._maybe_check_integrity(concat_axis) 581 582 return concat_axis c: users limyj0708 documents python lib site-packages pandas core reshape concat.py in _maybe_check_integrity(self, concat_index) 586 if not concat_index.is_unique: 587 overlap = concat_index[concat_index.duplicated()].unique() --&gt; 588 raise ValueError(f&#34;Indexes have overlapping values: {overlap}&#34;) 589 590 ValueError: Indexes have overlapping values: Index([&#39;a&#39;], dtype=&#39;object&#39;) . . 4-2. Merge : Database&#51032; Join&#52376;&#47100; Dataframe &#54633;&#52824;&#44592; . DataFrame.merge(right, how=&#39;inner&#39;, on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=(&#39;_x&#39;, &#39;_y&#39;), copy=True, indicator=False, validate=None) . right : 합칠 Dataframe | how : {‘left’, ‘right’, ‘outer’, ‘inner’, ‘cross’}, default ‘inner’ left: use only keys from left frame, similar to a SQL left outer join; preserve key order. | right: use only keys from right frame, similar to a SQL right outer join; preserve key order. | outer: use union of keys from both frames, similar to a SQL full outer join; sort keys lexicographically. | inner: use intersection of keys from both frames, similar to a SQL inner join; preserve the order of the left keys. | cross: creates the cartesian product from both frames, preserves the order of the left keys. | . | on : label or list 조인할 컬럼이나 인덱스 레벨의 이름. 두 Dataframe에 무조건 있어야 한다. | . | left_on : label or list, or array-like 왼쪽 Dataframe의 조인할 컬럼이나 인덱스 레벨의 이름. | . | right_on : label or list, or array-like 오른쪽 Dataframe의 조인할 컬럼이나 인덱스 레벨의 이름. | . | left_index : bool, default False 왼쪽 index를 조인의 key로 사용할까요? | MultiIndex인 경우, 상대 Dataframe의 key 수가 level의 수와 동일해야 함. | . | right_index : bool, default False 오른쪽 index를 조인의 key로 사용할까요? | MultiIndex인 경우, 상대 Dataframe의 key 수가 level의 수와 동일해야 함. | . | sort : bool, default False 조인 결과 Dataframe에서 key를 사전 순서(lexicographically)로 배열함 | False인 경우, 조인 방법에 정의된 방법을 따라감 | . | suffixes : list-like, default is (“_x”, “_y”) 컬럼에 접미사를 붙인다. 왼쪽 오른쪽 구분용. | 기본적으로 왼쪽에 _x, 오른쪽에 _y가 붙는다. | . | copy : bool, default True False면, 가능하면 복사를 피한다. | . | indicator : bool or str, default False | validate : str, optional If specified, checks if merge is of specified type. “one_to_one” or “1:1”: check if merge keys are unique in both left and right datasets. | “one_to_many” or “1:m”: check if merge keys are unique in left dataset. | “many_to_one” or “m:1”: check if merge keys are unique in right dataset. | “many_to_many” or “m:m”: allowed, but does not result in checks. | . | . | . df1 = pd.DataFrame({&#39;lkey&#39;: [&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;, &#39;foo&#39;], &#39;value&#39;: [1, 2, 3, 5]}) df2 = pd.DataFrame({&#39;rkey&#39;: [&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;, &#39;foo&#39;], &#39;value&#39;: [5, 6, 7, 8]}) display(df1) display(df2) . lkey value . 0 foo | 1 | . 1 bar | 2 | . 2 baz | 3 | . 3 foo | 5 | . rkey value . 0 foo | 5 | . 1 bar | 6 | . 2 baz | 7 | . 3 foo | 8 | . display(df1.merge(df2, left_on=&#39;lkey&#39;, right_on=&#39;rkey&#39;)) # 뒤에 _x, _y가 붙은 것을 확인. df1.merge(df2, left_on=&#39;lkey&#39;, right_on=&#39;rkey&#39;, suffixes=(&#39;_left&#39;, &#39;_right&#39;)) # _left, _right로 바꿔 보았음 . lkey value_x rkey value_y . 0 foo | 1 | foo | 5 | . 1 foo | 1 | foo | 8 | . 2 foo | 5 | foo | 5 | . 3 foo | 5 | foo | 8 | . 4 bar | 2 | bar | 6 | . 5 baz | 3 | baz | 7 | . lkey value_left rkey value_right . 0 foo | 1 | foo | 5 | . 1 foo | 1 | foo | 8 | . 2 foo | 5 | foo | 5 | . 3 foo | 5 | foo | 8 | . 4 bar | 2 | bar | 6 | . 5 baz | 3 | baz | 7 | . df1 = pd.DataFrame({&#39;a&#39;: [&#39;foo&#39;, &#39;bar&#39;], &#39;b&#39;: [1, 2]}) df2 = pd.DataFrame({&#39;a&#39;: [&#39;foo&#39;, &#39;baz&#39;], &#39;c&#39;: [3, 4]}) display(df1) display(df2) . a b . 0 foo | 1 | . 1 bar | 2 | . a c . 0 foo | 3 | . 1 baz | 4 | . df1.merge(df2, how=&#39;inner&#39;, on=&#39;a&#39;) # a 컬럼을 키로 잡음. 두 Dataframe에 다 a 컬럼이 있어서 가능한것 # inner join . a b c . 0 foo | 1 | 3 | . df1.merge(df2, how=&#39;left&#39;, on=&#39;a&#39;) # left outer join . a b c . 0 foo | 1 | 3.0 | . 1 bar | 2 | NaN | . df1.merge(df2, how=&#39;left&#39;, left_on=&#39;a&#39;, right_on=&#39;a&#39;) # left outer join . a b c . 0 foo | 1 | 3.0 | . 1 bar | 2 | NaN | . 4-2-1. Dataframe Join&#51032; &#49549;&#46020;&#47484; &#54693;&#49345;&#49884;&#53412;&#44592; &#50948;&#54644;&#49436;&#45716;? . https://stackoverflow.com/questions/40860457/improve-pandas-merge-performance | key를 index로 사용한다. index 검색 시에는 hash table을 이용하기 때문A short explanation why it is faster to merge by index instead of by a &quot;normal&quot; column:Indices have a hash table. Meaning you can look them up in amortized O(1). For a normal column you need O(n) in worst case, meaning merging two dfs with len n takes O(n^2) in worst case.- join을 쓴다. . | . | concat을 쓴다. | . 여기서의 결론 : key를 index로 사용한 후 join을 쓴다. . import random df1 = pd.DataFrame({&#39;uid_sample&#39;: random.sample(range(100000), 80000), &#39;value&#39;: random.sample(range(10000000), 80000)}) df2 = pd.DataFrame({&#39;userId_sample2&#39;: random.sample(range(100000), 80000), &#39;value&#39;: random.sample(range(10000000), 80000)}) # 80000명의 정보를 담고 있는 두 Dataframe이 있다고 하자. # uid_sample, userId_sample2를 key로 조인하고 싶다. . %%timeit df1.merge(df2, how=&#39;left&#39;, left_on=&#39;uid_sample&#39;, right_on=&#39;userId_sample2&#39;) . 19.4 ms ± 981 µs per loop (mean ± std. dev. of 7 runs, 10 loops each) . %%timeit # key로 사용하려는 컬럼을 index로 할당 # 36%정도 빨라졌다! df3 = df1.set_index(&#39;uid_sample&#39;) df4 = df2.set_index(&#39;userId_sample2&#39;) df3.merge(df4, right_index=True, left_index=True) . 12.6 ms ± 181 µs per loop (mean ± std. dev. of 7 runs, 100 loops each) . %%timeit # key로 사용하려는 컬럼을 index로 할당 # join 함수 사용 # 여기서 이미 2.5배 빨라졌다 df3 = df1.set_index(&#39;uid_sample&#39;) df4 = df2.set_index(&#39;userId_sample2&#39;) df3.join(df4, how=&#39;left&#39;, lsuffix=&#39;left&#39;, rsuffix=&#39;right&#39;) . 8.04 ms ± 1.21 ms per loop (mean ± std. dev. of 7 runs, 100 loops each) . %%timeit # inner, outer밖에 안 되는데 join보다 느리다. df3 = df1.set_index(&#39;uid_sample&#39;) df4 = df2.set_index(&#39;userId_sample2&#39;) pd.concat([df3, df4], axis=1, join=&#39;inner&#39;) . 11.5 ms ± 341 µs per loop (mean ± std. dev. of 7 runs, 100 loops each) . 4-3. Join : Merge&#48372;&#45796; &#48736;&#47476;&#45796; . DataFrame.join(other, on=None, how=&#39;left&#39;, lsuffix=&#39;&#39;, rsuffix=&#39;&#39;, sort=False) . other : 다른 데이터프레임, 혹은 시리즈, 혹은 데이터프레임 리스트 함수를 호출한 데이터프레임에 붙일 대상 | . | on : 조인 키가 될 컬럼 이름, 혹은 컬럼 이름 리스트(array-like 자료형이면 됨) | how left : 함수를 호출한 데이터프레임(caller)의 index를 조인 키로 사용. on에서 컬럼을 지정했을 경우, 그 컬럼을 사용 | right : other 패러미터에 할당된 객체의 index를 사용 | outer : outer join 실행 후, 사전 순으로 정렬함. 기본적으론 양쪽 다 index를 사용. on에서 지정하면 caller만 해당 컬럼 사용. | inner : inner join 실행. caller의 순서 보존됨. | cross : 양쪽의 곱집합 생성. left key(caller)의 순서 보존됨. | . | lsuffix, rsuffix : join된 결과물 컬럼의 접미사 세팅. | sort : TRUE면, join key의 사전 순서대로 정렬됨. FALSE면, how에서의 기본 처리방식을 따름. | . caller = pd.DataFrame({&#39;key&#39;: [&#39;K0&#39;, &#39;K1&#39;, &#39;K2&#39;, &#39;K3&#39;, &#39;K4&#39;, &#39;K5&#39;], &#39;A&#39;: [&#39;A0&#39;, &#39;A1&#39;, &#39;A2&#39;, &#39;A3&#39;, &#39;A4&#39;, &#39;A5&#39;]}) other = pd.DataFrame({&#39;key&#39;: [&#39;K0&#39;, &#39;K1&#39;, &#39;K2&#39;], &#39;B&#39;: [&#39;B0&#39;, &#39;B1&#39;, &#39;B2&#39;]}) other2 = pd.DataFrame({&#39;key&#39;: [&#39;K0&#39;, &#39;K1&#39;, &#39;K2&#39;], &#39;C&#39;: [&#39;C0&#39;, &#39;C1&#39;, &#39;C2&#39;]}) . caller_styler = caller.style.set_table_attributes(&quot;style=&#39;display:inline;margin:5px&#39;&quot;).set_caption(&#39;caller&#39;) other_styler = other.style.set_table_attributes(&quot;style=&#39;display:inline;margin:5px&#39;&quot;).set_caption(&#39;other&#39;) other2_styler = other2.style.set_table_attributes(&quot;style=&#39;display:inline;margin:5px&#39;&quot;).set_caption(&#39;other2&#39;) display_html(caller_styler._repr_html_() + other_styler._repr_html_() + other2_styler._repr_html_(), raw=True) . caller key A . 0 K0 | A0 | . 1 K1 | A1 | . 2 K2 | A2 | . 3 K3 | A3 | . 4 K4 | A4 | . 5 K5 | A5 | . other key B . 0 K0 | B0 | . 1 K1 | B1 | . 2 K2 | B2 | . other2 key C . 0 K0 | C0 | . 1 K1 | C1 | . 2 K2 | C2 | . caller.join(other, lsuffix=&#39;_caller&#39;, rsuffix=&#39;_other&#39;) . key_caller A key_other B . 0 K0 | A0 | K0 | B0 | . 1 K1 | A1 | K1 | B1 | . 2 K2 | A2 | K2 | B2 | . 3 K3 | A3 | NaN | NaN | . 4 K4 | A4 | NaN | NaN | . 5 K5 | A5 | NaN | NaN | . caller.set_index(&#39;key&#39;).join(other.set_index(&#39;key&#39;)) . A B . key . K0 A0 | B0 | . K1 A1 | B1 | . K2 A2 | B2 | . K3 A3 | NaN | . K4 A4 | NaN | . K5 A5 | NaN | . # on에다 조인 키로 쓰고 싶은 caller의 컬럼을 할당하는 방법이 있음 caller.join(other.set_index(&#39;key&#39;), on=&#39;key&#39;) . key A B . 0 K0 | A0 | B0 | . 1 K1 | A1 | B1 | . 2 K2 | A2 | B2 | . 3 K3 | A3 | NaN | . 4 K4 | A4 | NaN | . 5 K5 | A5 | NaN | . # 즉, on을 쓰지 못한다는 이야기이다. caller.set_index(&#39;key&#39;).join([other.set_index(&#39;key&#39;), other2.set_index(&#39;key&#39;)]) . A B C . key . K0 A0 | B0 | C0 | . K1 A1 | B1 | C1 | . K2 A2 | B2 | C2 | . K3 A3 | NaN | NaN | . K4 A4 | NaN | NaN | . K5 A5 | NaN | NaN | . 5. &#45936;&#51060;&#53552; &#51116;&#44396;&#51312;&#54868; . 5.1 Pivot : &#50641;&#49472;&#50640;&#49436; &#48372;&#45912; &#44536;&#44163; . DataFrame.pivot(index=None, columns=None, values=None) . index : str or object or a list of str, optional 새로운 프레임의 index로 사용할 컬럼 | . | columns : str of object or a list of str 새로운 프레임의 컬럼으로 사용할 컬럼 | . | values : str, object or a list of the previous, optional 새로운 프레임의 값을 계산하기 위해 사용하는 컬럼 | 지정하지 않으면, 남아있는 모든 컬럼을 사용한다. | . | . df = pd.DataFrame({&#39;foo&#39;: [&#39;one&#39;, &#39;one&#39;, &#39;one&#39;, &#39;two&#39;, &#39;two&#39;, &#39;two&#39;], &#39;bar&#39;: [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;A&#39;, &#39;B&#39;, &#39;C&#39;], &#39;baz&#39;: [1, 2, 3, 4, 5, 6], &#39;zoo&#39;: [&#39;x&#39;, &#39;y&#39;, &#39;z&#39;, &#39;q&#39;, &#39;w&#39;, &#39;t&#39;]}) df . foo bar baz zoo . 0 one | A | 1 | x | . 1 one | B | 2 | y | . 2 one | C | 3 | z | . 3 two | A | 4 | q | . 4 two | B | 5 | w | . 5 two | C | 6 | t | . df.pivot(index=&#39;foo&#39;, columns=&#39;bar&#39;, values=&#39;baz&#39;) . bar A B C . foo . one 1 | 2 | 3 | . two 4 | 5 | 6 | . df.pivot(index=&#39;foo&#39;, columns=&#39;bar&#39;) . baz zoo . bar A B C A B C . foo . one 1 | 2 | 3 | x | y | z | . two 4 | 5 | 6 | q | w | t | . df.pivot(index=&#39;foo&#39;, columns=&#39;bar&#39;)[&#39;baz&#39;] . bar A B C . foo . one 1 | 2 | 3 | . two 4 | 5 | 6 | . df = pd.DataFrame({ &quot;lev1&quot;: [1, 1, 1, 2, 2, 2], &quot;lev2&quot;: [1, 1, 2, 1, 1, 2], &quot;lev3&quot;: [1, 2, 1, 2, 1, 2], &quot;lev4&quot;: [1, 2, 3, 4, 5, 6], &quot;values&quot;: [0, 1, 2, 3, 4, 5]}) df . lev1 lev2 lev3 lev4 values . 0 1 | 1 | 1 | 1 | 0 | . 1 1 | 1 | 2 | 2 | 1 | . 2 1 | 2 | 1 | 3 | 2 | . 3 2 | 1 | 2 | 4 | 3 | . 4 2 | 1 | 1 | 5 | 4 | . 5 2 | 2 | 2 | 6 | 5 | . df.pivot(index=&quot;lev1&quot;, columns=[&quot;lev2&quot;, &quot;lev3&quot;] ,values=&quot;values&quot;) # Multilevel Column # 해당하는 조건에 맞는 값이 없으면 NaN이 들어가게 됨 . lev2 1 2 . lev3 1 2 1 2 . lev1 . 1 0.0 | 1.0 | 2.0 | NaN | . 2 4.0 | 3.0 | NaN | 5.0 | . df.pivot(index=[&quot;lev1&quot;, &quot;lev2&quot;], columns=[&quot;lev3&quot;],values=&quot;values&quot;) # Multiindex . lev3 1 2 . lev1 lev2 . 1 1 0.0 | 1.0 | . 2 2.0 | NaN | . 2 1 4.0 | 3.0 | . 2 NaN | 5.0 | . df.pivot(index=[&quot;lev1&quot;], columns=[&quot;lev2&quot;],values=&quot;values&quot;) # 인덱스, 컬럼 쌍에 중복이 발생하면 에러가 출력됨 # ValueError: Index contains duplicate entries, cannot reshape . ValueError Traceback (most recent call last) &lt;ipython-input-228-cdcd62e9b0d4&gt; in &lt;module&gt; -&gt; 1 df.pivot(index=[&#34;lev1&#34;], columns=[&#34;lev2&#34;],values=&#34;values&#34;) c: users limyj0708 documents python lib site-packages pandas core frame.py in pivot(self, index, columns, values) 6676 from pandas.core.reshape.pivot import pivot 6677 -&gt; 6678 return pivot(self, index=index, columns=columns, values=values) 6679 6680 _shared_docs[ c: users limyj0708 documents python lib site-packages pandas core reshape pivot.py in pivot(data, index, columns, values) 475 else: 476 indexed = data._constructor_sliced(data[values]._values, index=index) --&gt; 477 return indexed.unstack(columns) 478 479 c: users limyj0708 documents python lib site-packages pandas core series.py in unstack(self, level, fill_value) 3900 from pandas.core.reshape.reshape import unstack 3901 -&gt; 3902 return unstack(self, level, fill_value) 3903 3904 # - c: users limyj0708 documents python lib site-packages pandas core reshape reshape.py in unstack(obj, level, fill_value) 422 if is_extension_array_dtype(obj.dtype): 423 return _unstack_extension_series(obj, level, fill_value) --&gt; 424 unstacker = _Unstacker( 425 obj.index, level=level, constructor=obj._constructor_expanddim, 426 ) c: users limyj0708 documents python lib site-packages pandas core reshape reshape.py in __init__(self, index, level, constructor) 118 raise ValueError(&#34;Unstacked DataFrame is too big, causing int32 overflow&#34;) 119 --&gt; 120 self._make_selectors() 121 122 @cache_readonly c: users limyj0708 documents python lib site-packages pandas core reshape reshape.py in _make_selectors(self) 167 168 if mask.sum() &lt; len(self.index): --&gt; 169 raise ValueError(&#34;Index contains duplicate entries, cannot reshape&#34;) 170 171 self.group_index = comp_index ValueError: Index contains duplicate entries, cannot reshape . . 5.2 Pivot_table : Pivot&#51032; &#54869;&#51109; &#48260;&#51204; . pandas.pivot_table(data, values=None, index=None, columns=None, aggfunc=&#39;mean&#39;, fill_value=None, margins=False, dropna=True, margins_name=&#39;All&#39;, observed=False, sort=True) . A B C D E . 0 foo | one | small | 1 | 2 | . 1 foo | one | large | 2 | 4 | . 2 foo | one | large | 2 | 5 | . 3 foo | two | small | 3 | 5 | . 4 foo | two | small | 3 | 6 | . 5 bar | one | large | 4 | 6 | . 6 bar | one | small | 5 | 8 | . 7 bar | two | small | 6 | 9 | . 8 bar | two | large | 7 | 9 | . table = pd.pivot_table(df, values=&#39;D&#39;, index=[&#39;A&#39;, &#39;B&#39;], columns=[&#39;C&#39;], aggfunc=np.sum) table # aggfunc에 집계함수를 넣게 된다. 여기서는 총합 . C large small . A B . bar one 4.0 | 5.0 | . two 7.0 | 6.0 | . foo one 4.0 | 1.0 | . two NaN | 6.0 | . table = pd.pivot_table(df, values=&#39;D&#39;, index=[&#39;A&#39;, &#39;B&#39;], columns=[&#39;C&#39;], aggfunc=np.sum, fill_value=0) table # fill_value에 할당된 값으로 NaN을 대체하게 됨 . C large small . A B . bar one 4 | 5 | . two 7 | 6 | . foo one 4 | 1 | . two 0 | 6 | . table = pd.pivot_table(df, values=[&#39;D&#39;, &#39;E&#39;], index=[&#39;A&#39;, &#39;C&#39;], aggfunc={&#39;D&#39;: np.mean, &#39;E&#39;: np.sum}) table # aggfunc에 Dictionary를 할당하여 값마다 집계함수를 각각 다르게 설정할 수 있다. . D E . A C . bar large 5.500000 | 15 | . small 5.500000 | 17 | . foo large 2.000000 | 9 | . small 2.333333 | 13 | . table = pd.pivot_table(df, values=[&#39;D&#39;, &#39;E&#39;], index=[&#39;A&#39;, &#39;C&#39;], aggfunc={&#39;D&#39;: np.mean, &#39;E&#39;: [min, max, np.mean]}) table # 한 값에 여러 개의 집계함수 할당도 가능하다. . D E . mean max mean min . A C . bar large 5.500000 | 9.0 | 7.500000 | 6.0 | . small 5.500000 | 9.0 | 8.500000 | 8.0 | . foo large 2.000000 | 5.0 | 4.500000 | 4.0 | . small 2.333333 | 6.0 | 4.333333 | 2.0 | . table = pd.pivot_table(df, values=[&#39;D&#39;, &#39;E&#39;], index=[&#39;A&#39;, &#39;C&#39;], aggfunc={&#39;D&#39;: np.mean, &#39;E&#39;: np.mean}, margins=True, margins_name=&quot;mean&quot;) table # Values에 적용된 집계함수를 컬럼 전체에 적용한 행을 추가한다. # 한 Value에 집계함수를 하나만 사용했을 때 적용 가능. # margins_name을 지정하지 않으면 기본적으로 행 Index 이름은 All이 된다. . D E . A C . bar large 5.500000 | 7.500000 | . small 5.500000 | 8.500000 | . foo large 2.000000 | 4.500000 | . small 2.333333 | 4.333333 | . mean 3.666667 | 6.000000 | . 5.3 melt : Unpivot &#54616;&#44592; . pandas.melt(frame, id_vars=None, value_vars=None, var_name=None, value_name=&#39;value&#39;, col_level=None, ignore_index=True) . id_vars : tuple, list, or ndarray, optional 식별자로 사용할 컬럼 | . | value_vars : tuple, list, or ndarray, optional Unpivot 할 컬럼. 지정하지 않으면, id_vars에 할당되지 않은 모든 컬럼을 사용 | . | . df = pd.DataFrame({&#39;A&#39;: {0: &#39;a&#39;, 1: &#39;b&#39;, 2: &#39;c&#39;}, &#39;B&#39;: {0: 1, 1: 3, 2: 5}, &#39;C&#39;: {0: 2, 1: 4, 2: 6}}) df . A B C . 0 a | 1 | 2 | . 1 b | 3 | 4 | . 2 c | 5 | 6 | . pd.melt(df, id_vars=[&#39;A&#39;], value_vars=[&#39;B&#39;]) . A variable value . 0 a | B | 1 | . 1 b | B | 3 | . 2 c | B | 5 | . pd.melt(df, id_vars=[&#39;A&#39;], value_vars=[&#39;B&#39;, &#39;C&#39;]) . A variable value . 0 a | B | 1 | . 1 b | B | 3 | . 2 c | B | 5 | . 3 a | C | 2 | . 4 b | C | 4 | . 5 c | C | 6 | . pd.melt(df, id_vars=[&#39;A&#39;], value_vars=[&#39;B&#39;], var_name=&#39;myVarname&#39;, value_name=&#39;myValname&#39;) # 이름은 커스터마이징 가능 . A myVarname myValname . 0 a | B | 1 | . 1 b | B | 3 | . 2 c | B | 5 | . pd.melt(df, id_vars=[&#39;A&#39;], value_vars=[&#39;B&#39;, &#39;C&#39;], ignore_index=False) # 원본 index 유지 . A variable value . 0 a | B | 1 | . 1 b | B | 3 | . 2 c | B | 5 | . 0 a | C | 2 | . 1 b | C | 4 | . 2 c | C | 6 | . 6. &#45936;&#51060;&#53552; &#53440;&#51077; . 6-1. dtypes : &#52972;&#47100;&#46308;&#51032; type &#52636;&#47141; . df = pd.DataFrame({&#39;float&#39;: [1.0], &#39;int&#39;: [1], &#39;datetime&#39;: [pd.Timestamp(&#39;20180310&#39;)], &#39;string&#39;: [&#39;foo&#39;]}) df.dtypes # 더 이상의 설명은 필요 없다! . float float64 int int64 datetime datetime64[ns] string object dtype: object . 6-2. select_dtypes : &#53945;&#51221; &#53440;&#51077;&#51032; &#52972;&#47100;&#51012; &#49440;&#53469;, &#54841;&#51008; &#48176;&#51228; . DataFrame.select_dtypes(include=None, exclude=None) . To select all numeric types, use np.number or &#39;number&#39; | To select strings you must use the object dtype, but note that this will return all object dtype columns See the numpy dtype hierarchy | To select datetimes, use np.datetime64, &#39;datetime&#39; or &#39;datetime64&#39; | To select timedeltas, use np.timedelta64, &#39;timedelta&#39; or &#39;timedelta64&#39; | To select Pandas categorical dtypes, use &#39;category&#39; | To select Pandas datetimetz dtypes, use &#39;datetimetz&#39; (new in 0.20.0) or &#39;datetime64[ns, tz]&#39; | . df = pd.DataFrame({&#39;a&#39;: [1, 2] * 3, &#39;b&#39;: [True, False] * 3, &#39;c&#39;: [1.0, 2.0] * 3}) df . a b c . 0 1 | True | 1.0 | . 1 2 | False | 2.0 | . 2 1 | True | 1.0 | . 3 2 | False | 2.0 | . 4 1 | True | 1.0 | . 5 2 | False | 2.0 | . df.select_dtypes(include=&#39;bool&#39;) . b . 0 True | . 1 False | . 2 True | . 3 False | . 4 True | . 5 False | . df.select_dtypes(include=[&#39;float64&#39;]) . c . 0 1.0 | . 1 2.0 | . 2 1.0 | . 3 2.0 | . 4 1.0 | . 5 2.0 | . df.select_dtypes(exclude=[&#39;int64&#39;]) . b c . 0 True | 1.0 | . 1 False | 2.0 | . 2 True | 1.0 | . 3 False | 2.0 | . 4 True | 1.0 | . 5 False | 2.0 | . 6-3. astype : &#53440;&#51077; &#48320;&#44221;. Bigquery&#50640; df &#50629;&#47196;&#46300; &#49884; &#48152;&#46300;&#49884; &#49324;&#50857; . DataFrame.astype(dtype, copy=True, errors=&#39;raise&#39;) . copy : False를 하면, 복사를 하는 게 아니고 원본에 연결되므로 변경사항이 원본에까지 전파됨 | errors : ignore로 세팅하면, 에러 발생 시 원본을 반환하고 끝냄 | . d = {&#39;col1&#39;: [1, 2], &#39;col2&#39;: [3, 4]} df = pd.DataFrame(data=d) df.dtypes . col1 int64 col2 int64 dtype: object . df.astype({&#39;col1&#39;: &#39;int32&#39;}).dtypes # 잘 변경됐습니다~ . col1 int32 col2 int64 dtype: object . 7. &#54028;&#51068; &#51077;&#52636;&#47141; . 7-1. read_excel : xlsx &#54028;&#51068;&#51012; &#51069;&#44592; &#50948;&#54644;&#49436;&#45716;? . string_quest = pd.read_excel(r&quot;C: Users limyj0708 Documents data string string_quest.xlsx&quot;, header=6, usecols=&quot;H,I&quot;, sheet_name = &quot;string_quest&quot;, engine=&quot;openpyxl&quot;) . header : 몇 번째 row를 header로 할까? | usercols : 어떤 열을 가져올까? | sheet_name : 어떤 시트를 가져올까? | engine : openpyxl을 사용하여야 xlsx 파일의 불러오기가 가능 | . 7-2. Dataframe&#51012; &#51060;&#48120;&#51648;&#47196; &#52628;&#52636; . matplotlib&#47484; &#51060;&#50857; . dataframe-image 패키지를 이용 시, linux에서 crontab으로 실행할 경우 복잡한 권한 문제에 직면하게 됨 | dataframe-image 패키지도 matplotlib 기반이므로, 그냥 matplotlib를 사용 | . import six import matplotlib.pyplot as plt import matplotlib.font_manager as fm # matplotlib에서 한글이 안 나오는 문제 해결 NANUM = fm.FontProperties(fname=r&#39;C: Users limyj0708 AppData Local Microsoft Windows Fonts NanumBarunGothic.ttf&#39;) NANUM_bold = fm.FontProperties(fname=r&#39;C: Users limyj0708 AppData Local Microsoft Windows Fonts NanumBarunGothicBold.ttf&#39;) # centos라면 폰트 경로는 아래와 같음 ## /usr/share/fonts/NanumFont/NanumBarunGothic.ttf ## /usr/share/fonts/NanumFont/NanumGothicBold.ttf def render_mpl_table(data, col_width=3.0, row_height=0.625, font_size_header=16, font_size=14, header_color=&#39;#C2DED1&#39;, row_colors=[&#39;#f1f1f2&#39;, &#39;w&#39;], edge_color=&#39;black&#39;, bbox=[0, 0, 1, 1], header_columns=0, ax=None, align_head=&#39;center&#39;, align_cell=&#39;center&#39;, **kwargs): &quot;&quot;&quot; align_head, align_cell : [ &#39;center&#39; | &#39;right&#39; | &#39;left&#39; ] &quot;&quot;&quot; if ax is None: size = (np.array(data.shape[::-1]) + np.array([0, 1])) * np.array([col_width, row_height]) fig, ax = plt.subplots(figsize=size) ax.axis(&#39;off&#39;) mpl_table = ax.table(cellText=data.values, bbox=bbox, colLabels=data.columns, **kwargs) mpl_table.auto_set_font_size(False) for k, cell in six.iteritems(mpl_table._cells): cell.set_edgecolor(edge_color) if k[0] == 0 or k[1] &lt; header_columns: cell.set_facecolor(header_color) cell.set_text_props(color=&#39;black&#39;, fontproperties = NANUM_bold, fontsize=font_size_header, ha=align_head) else: cell.set_facecolor(row_colors[k[0]%len(row_colors)]) cell.set_text_props(fontproperties = NANUM, fontsize=font_size, ha=align_cell) return ax image = render_mpl_table(caller, col_width=2.0, align_head=&#39;left&#39;) image image.figure.savefig(&quot;caller.png&quot;) # 이미지 저장 # crontab으로 돌릴 것이라면 이미지 저장 경로도 절대경로로 지정 .",
            "url": "https://limyj0708.github.io/fastpages/python/pandas/2021/11/05/pandas_cheatsheet.html",
            "relUrl": "/python/pandas/2021/11/05/pandas_cheatsheet.html",
            "date": " • Nov 5, 2021"
        }
        
    
  
    
        ,"post8": {
            "title": "Crontab으로 Python 스크립트 주기적으로 실행하기",
            "content": "주기적으로 외부 API를 통해 데이터를 수집하여, Bigquery에 적재하고 싶다. CentOS 서버에서, 주기적으로 Python 스크립트를 실행하여 해결해 보자. . sudo crontab -e : crontab 설정 오픈. 자동으로 root가 작업하는 것으로 인지됨 | 설정 경로는 절대경로를 입력해야 제대로 작동 Python 경로도 절대경로로 입력해 줘야 함 | . | 시간설정은 아래 링크에서 직관적으로 확인 가능 Crontab.guru - The cron schedule expression editor | . | | 30 8 * * * /usr/local/bin/python3.9 /home/limyj0708/cw_daily_bigquery/cw_daily.py . cron 재시작 재시작해야 적용됨 | service cron restart | CentOS일 경우, service crond restart | |",
            "url": "https://limyj0708.github.io/fastpages/linux/2021/09/07/Crontab%EC%9C%BC%EB%A1%9C-Python-%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8-%EC%A3%BC%EA%B8%B0%EC%A0%81%EC%9C%BC%EB%A1%9C-%EC%8B%A4%ED%96%89%ED%95%98%EA%B8%B0.html",
            "relUrl": "/linux/2021/09/07/Crontab%EC%9C%BC%EB%A1%9C-Python-%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8-%EC%A3%BC%EA%B8%B0%EC%A0%81%EC%9C%BC%EB%A1%9C-%EC%8B%A4%ED%96%89%ED%95%98%EA%B8%B0.html",
            "date": " • Sep 7, 2021"
        }
        
    
  
    
        ,"post9": {
            "title": "Linux 비밀번호 만료 안 되게 하기",
            "content": "1. 빠른 결론 . chage -E -1 -M 99999 계정명 . 2. 각 명령어 구성품의 의미 . chage : 사용자의 패스워드 정보를 관리하는 명령어 -E : 계정의 만료일 설정 | -l : 지정한 계정의 정보를 보여 줌 | -M : 패스워드 최종 변경일로부터 패스워드 변경 없이 사용할 수 있는 최대 일수를 설정 | . | -E에는 -1을 할당 : 영원히 계정을 만료시키지 않음 | -M에는 99999를 할당 : 패스워드 변경 이후 99999일 동안 변경 없이 사용 가능 . | 위의 명령어 입력 후, sudo chage -l 계정명 으로 계정/패스워드 정보를 확인해 보면 아래와 같다. . Last password change : Aug 23, 2021 Password expires : never Password inactive : never Account expires : never Minimum number of days between password change : 5 Maximum number of days between password change : 99999 Number of days of warning before password expires : 7 . | . 3. Reference . 리눅스 패스워드 만료 안되게 하기 - 제타위키 (zetawiki.com) [Linux] chage 명령어 (사용자 패스워드 만기 정보 관리) (tistory.com) .",
            "url": "https://limyj0708.github.io/fastpages/linux/2021/09/06/Linux_%EB%B9%84%EB%B0%80%EB%B2%88%ED%98%B8-%EB%A7%8C%EB%A3%8C-%EC%95%88-%EB%90%98%EA%B2%8C-%ED%95%98%EA%B8%B0.html",
            "relUrl": "/linux/2021/09/06/Linux_%EB%B9%84%EB%B0%80%EB%B2%88%ED%98%B8-%EB%A7%8C%EB%A3%8C-%EC%95%88-%EB%90%98%EA%B2%8C-%ED%95%98%EA%B8%B0.html",
            "date": " • Sep 6, 2021"
        }
        
    
  
    
        ,"post10": {
            "title": "<Docker> Mac에 Oracle DB 설치하기로 Docker 시작하기",
            "content": "새로운 도구의 필요성은 언제나 갑자기 찾아온다. “오너라, 오라클! 난 Docker 마스터다! 널 맥에 바로 설치해주마!” 같은 상황은 살면서 별로 일어나지 않는다. . 그렇다고 구글링을 해서 나온 명령어들을 그저 복사&amp;붙여넣기 하여 설치하기만 하면, 응용도 안 되고 단지 시간을 쓴 것에 지나지 않게 된다. . 단순한 따라하기를 넘어서, Docker로 Oracle DB를 Mac에 설치하는 과정을 통해 Docker의 개념과 기본 명령어들을 공부해보자. 일단 설치부터 하고~ Docker Desktop for mac . Docker가 뭐요? . 일단 Nomad Coders의 영상을 본 다음에, 좋은 소개 자료들을 읽어보자. . Docker 공식 문서 / Docker Overview | Docker 공식 문서 / Container 개념 소개 페이지 | 초보를 위한 도커 안내서 - 도커란 무엇인가? | . Docker Overview 페이지와 Wikipedia의 설명을 요약하면, 아래와 같이 정리할 수 있지 않을까? . ‘Container’라 불리는 단위로 어플리케이션을 묶고, 인프라로부터 분리하여, 인프라에 종속되지 않는 어플리케이션 실행과 빠른 배포를 가능하게 하는 플랫폼 . Docker의 구조 . Docker Engine . 다음은 Docker Engine의 구조이다. 서버-클라이언트 형식으로 되어 있다.이 Docker Engine 위에서 Container가 돌아가고, 이런저런 관리를 하게 된다. . . Daemon 프로세스인 서버가 돌아가고 있다. . | REST API : 프로그램들이 deamon과 통신하고 뭘 해야 할 지 명령할 때, 사용할 수 있는 인터페이스를 명시하는 REST API. . | CLI Client : AWS CLI 처럼 HTTP API WRAPPER로서 기능함. 아래 설명을 잘 읽어 보자. . When you use docker run command to start up a Container, your docker client will translate that command into http API call, sends it to docker daemon, Docker daemon then evaluates the request, talks to underlying os and provisions your Container. . | . Docker Architecture . . . Client가 Daemon에게 요청을 보낸다. Client와 Daemon은 같은 시스템에서 작동할 수도 있고, | Client가 별도 서버의 Daemon에 접속할 수도 있다. | . | Client와 Daemon은 UNIX Socket(로컬에서 돌아갈 때)이나 네트워크 인터페이스를 통해, REST API로 통신한다. | . The Docker daemon . Docker daemon(dockerd)는 Docker API의 요청을 받아서, Docker Object(image, Container, network, volume…)들을 관리한다. | Docker service들을 관리하기 위해 다른 daemon들과 통신할 수도 있음. | . The Docker client . Docker client(docker) : Docker와 상호작용 하기 위한 가장 주요한 방법! e.g : docker run명령어를 실행하면, client는 dockerd에 이 명령어를 보낸다. docker명령은 Docker API를 사용한다. | 여러 개의 daemon과 통신할 수도 있다. | . Docker registries . Docker image들의 저장장소. Docker Hub라는 Public registy가 제공된다. (image를 찾을 때, 찾는 장소는 Docker Hub가 기본값이다!) Private registry도 사용 가능. | Docker Datacenter를 사용한다면, Docker Trusted Registy가 포함되어 있다. (이 내용은 나중에 알아보자.) | . Docker objects : Container? image? . Image . Image는 Container를 만들기 위한 명령들이 들어 있는 읽기 전용 템플릿이다. | Image를 만들기 위해서는 Dockerfile을 만들어야 한다. Dockerfile은 image를 만들고 실행하는데 필요한 단계들을 정의하는 구문들을 담고 있는 파일이다. | Dockerfile의 각 명령들은 image의 각 layer들을 생성한다. Dockerfile을 수정하고 다시 빌드하면, 바꾼 layer만 변경된다. 그래서 다른 가상화 기술에 비해 가볍고 작고 빠르다. | . | Image는 상태(state)를 가지지 않으며, 변하지 않는다.(Container의 설계도가 상황에 따라 이리저리 변하면 곤란할 것이다.) | Layer로 구성된 특성 덕분에, 특정 이미지를 약간 수정한 다른 이미지를 쉽게 만들 수 있다. e.g. Ubuntu 이미지를 기반으로, Ubuntu에 Node.js를 설치한 다른 이미지 생성. | . | . 위의 설명을 시각화하면 아래처럼 된다. . Container (is a runnable instance of image) . 제목에 써 있는 대로, image의 인스턴스. image가 실행된 상태. | Docker 공식 Container 소개 페이지에 따르면, 아래와 같은 컨셉으로 작동한다. VM은 비교를 위해 언급되어 있다. | . . Containers Containers are an abstraction at the app layer that packages code and dependencies together. Multiple Containers can run on the same machine and share the OS kernel with other Containers, each running as isolated processes in user space. Containers take up less space than VMs (Container images are typically tens of MBs in size), can handle more applications and require fewer VMs and Operating systems. . VIRTUAL MACHINES Virtual machines (VMs) are an abstraction of physical hardware turning one server into many servers. The hypervisor allows multiple VMs to run on a single machine. Each VM includes a full copy of an operating system, the application, necessary binaries and libraries - taking up tens of GBs. VMs can also be slow to boot. . Container의 특징들 . Docker API, CLI로 만들고(create) 시작하고(start) 멈추고(stop) 옮기고(move) 할 수 있다. | 하나 혹은 여러 네트워크에 연결하고, 저장소를 추가하고, Container의 현재 상태를 기반으로 새 image도 만들 수 있다. | 기본적으로는, Container는 다른 Container, 자신의 Host와 잘 분리되어 있으며, 이 격리 상태도 조정할 수 있다. | Container는 (image) + (생성, 실행 시 받는 구성 옵션 값)에 의해 정의된다.(configuration option) | Container가 삭제될 때에는, 영구 저장소에 저장되지 않은 상태 변경 값은 사라진다. 그렇다. 모든 변경 사항은 Container의 R/W Layer에 저장되며, 이 Layer는 Container가 삭제되면 같이 사라진다. | . docker run 명령어 예시로 알아보는 Container 생성과정 % docker run -i -t ubuntu /bin/bash 위의 명령어를 실행하면, ubuntu Container를 만들고 실행해서 로컬 command-line 세션에 붙이고, Ubuntu의 Bash Shell을 실행한다. 어떤 일이 일어나는걸까? . ubuntu image가 로컬에 없으면, Docker가 image를 내가 설정해 둔 registry에서 pull한다. docker pull ubuntu를 직접 입력한 것처럼. (기본 registry는 Docker Hub) | Docker가 새 Container를 만든다. docker Container create를 직접 입력한 것처럼. | Docker가 읽고 쓰기가 가능한 파일시스템을 Container의 최종 레이어로써 할당한다.(R/W Layer) 이는 Container가 로컬 파일시스템에서 파일과 디렉토리를 만들고 수정할 수 있게 해 준다. | 네트워크 옵션을 하나도 주지 않았기 때문에, Docker가 Container를 기본 네트워크에 연결하기 위해 네트워크 인터페이스를 만든다. 이 과정은 IP 주소를 Container에 할당하는 과정이 포함된다. 자연스럽게, Container는 host의 네트워크 연결을 사용하여 외부 네트워크에 접속할 수 있게 된다. | Docker가 Container를 켠 후 /bin/bash를 실행한다. Container는 상호작용이 가능하게(interactively) 동작하고 있고, 터미널에 붙어 있기 때문에 (-i,-t 플래그를 넣어서), 키보드로 명령을 입력할 수 있고, 출력을 터미널로 받아볼 수 있다. | /bin/bash명령을 끄기 위해 exit를 입력하면, Container는 멈추지만 제거되지는 않는다. 다시 시작하거나 제거할 수 있다. | Services . (이 내용은 당장 활용할 일이 없다. 이후 사용의 필요가 느껴지면 심도있게 알아보자.) (Swarm에 대해 소개하는 아주 좋은 글) Service는 여러 개의 Docker daemon위에서 Container를 스케일링 할 수 있게 해준다. 이 여러 개의 Docker daemon들은 Swarm이라는, 여러 개의 manager, worker를 가지고 있는 단위로 뭉쳐서 작동한다. Swarm의 각 멤버들은 Docker daemon이고, daemon들은 Docker API를 사용하여 통신한다. Service는 원하는 상태를 정의할 수 있게 해 주는데, 특정 시간에 반드시 접근 가능해야 하는 Service 복제체의 숫자라던가 하는 것이다. 기본적으로, Service는 모든 worker node들에 부하 분산처리된다.(load-balanced) 사용자에게는 Docker service가 하나의 어플리케이션으로 보인다. Docker 1.12버전 이상부터 지원됨! . 여기까지 읽었을 때의 궁금한 점들 . Daemon이 뭐지? . https://en.wikipedia.org/wiki/Daemon_(computing) In multitasking computer operating systems, a daemon (/ˈdiːmən/ or /ˈdeɪmən/)[1] is a computer program that runs as a background process, rather than being under the direct control of an interactive user. 악마는 당신의 등 뒤에서 조용히 돌아가고 있다… :) . Rest API가 뭐지? . REpresentational State Transfer 이 영상 이상으로 잘 설명한 자료가 있을까?내용이 방대하기 때문에, 추후 별도의 정리를 진행해야겠다. . youtube: https://www.youtube.com/watch?v=RP_f5dMoHFc . Socket이 뭐지? . 프로세스 간 데이터 교환을 위한, 소프트웨어로 작성된 통신 접속점 아래는 Unix Socket(Unix Domain Socket)과 IP Socket에 대한 설명이다. . https://serverfault.com/questions/124517/whats-the-difference-between-unix-socket-and-tcp-ip-socket A UNIX socket is an inter-process communication mechanism that allows bidirectional data exchange between processes running on the same machine. IP sockets (especially TCP/IP sockets) are a mechanism allowing communication between processes over the network. In some cases, you can use TCP/IP sockets to talk with processes running on the same computer (by using the loopback interface). UNIX domain sockets know that they’re executing on the same system, so they can avoid some checks and operations (like routing); which makes them faster and lighter than IP sockets. So if you plan to communicate with processes on the same host, this is a better option than IP sockets. . 아래 글들도 읽어보도록 하자. . 소켓과 포트 | 소켓 프로그래밍 | 소켓 프로그래밍 기초 | 번외 : 서버,클라이언트,호스트 | . 그래서 선생, 이 명령어가 도대체 뭐요? . 어떤 명령어들을 사용하였는가 . Oracle DB 설치와 실행을 위해 어떤 명령어들을 사용하였는가? (클릭하면 각 명령어 설명 공식문서로 이동함) . docker search oracle : 기본 registry인 docker hub에서, oracle이라는 단어를 포함한 image를 찾는다. 추천수 순으로 정렬되어 나온다. 그런데 솔직히 Docker Hub에서 검색하는 것이 더 좋다. . | docker pull oracleinanutshell/oracle-xe-11g : registry에서 image나 repository를 가져온다. 여기서는 추천수가 가장 높았던 oracleinanutshell/oracle-xe-11g 라는 image를 가져왔다. Docker Hub : oracleinanutshell/oracle-xe-11g 설명을 보니 Ubuntu 18.04 LTS에 Oracle xe 11g를 올린 image다. . | docker run --name oracle-xe-11g -d -p 8080:8080 -p 1521:1521 oracleinanutshell/oracle-xe-11g : docker run [OPTIONS] image [COMMAND] [ARG...] 이런 구조로 되어있다. Container를 생성하여 실행한다. 여기서 사용한 옵션값부터 살펴보자. --name : Container의 이름을 설정한다. 중복 이름은 허용하지 않음. | -d : Container를 백그라운드에서 실행하고, Container ID를 출력한다. Background와 Foreground의 차이 | -p : 특정 범위의 포트, 혹은 포트 하나를 host에 publish한다. 여기서는 hostPort:ContainerPort 구조로 사용했다. 즉, Container의 8080포트를 Host의 8080포트에 매핑하는 방화벽 규칙을 만든다. (하필이면 8080, 1521인 이유는, Oracle Listener가 사용하는 포트가 1521이고, XML DB가 8080포트를 사용하기 때문이다.) docker port oracle-xe-11g로 연결된 포트를 확인해보면, 다음과 같이 뜬다. 1521/tcp -&gt; 0.0.0.0:1521 8080/tcp -&gt; 0.0.0.0:8080 . 포트들이 0.0.0.0 (all IPv4 addresses on the local machine)의 동일 포트에 매핑되었다. 이제 Container가 생성된 후 실행되었는데, 그럼 다음엔 뭘 해야 할까? . 참고 공식 문서 : Container networking | 참고 공식 문서 : Docker run reference | . | . | docker exec -it oracle-xe-11g bash : 외부에서, 실행 중인 Container 안의 명령을 실행한다. oracle-xe-11g Container는 Ubuntu 18.04위에서 Oracle DB를 구동하는 구조이기 때문에, bash shell을 열라는 명령어를 보내 보았다.(bash) 옵션 -it는 뭘까? -i : 키보드, 화면을 통해 STDIN, STDOUT(표준입력, 표준출력)[설명][설명의 번역]을 열고 유지한다. 명령어 입력, 결과 출력을 위해서 넣어주어야 하는 값이다. | -t : pseudo-TTY를 할당한다. 터미널 환경을 에뮬레이션 해 주는데, 이 옵션을 입력하지 않으면 터미널 환경이 보이지 않는다.(i와 t값을 넣지 않으면 각각 어떻게 되는가? 는 이 블로그를 참고하자.) 보기만 해서는 잘 기억나지 않을테니, 직접 해보자. % docker exec oracle-xe-11g bash % . 하나도 안 쓰면 바로 종료된다. 입출력도, tty도 활성화되지 않았으니 당연한 결과. % docker exec -t oracle-xe-11g bash root@a702ae5d7f10:/# sqlplus . | . -t만 쓰면, 첫 번째 명령어 입력까지는 가능하나 그 후의 결과가 출력되지 않는다. STDIN을 열지 않았으니 당연한 결과. . % docker exec -i oracle-xe-11g bash sqlplus bash: line 1: sqlplus: command not found ls bin boot dev …(이하생략) . -i만 쓰면, 터미널 환경이 조성되지 않는다. 그냥 명령어를 입력하면 sqlplus는 command not found 에러가 뜨고, ls는 제대로 출력이 되긴 한다. 응용 프로그램(sqlplus) 실행은 안 되고, 기본 shell command는 제대로 실행되는 건 terminal의 부재 때문이 아닌가 추측해본다. 자세한 이유는 다음에 알아보기로 하자.&lt;br&gt; . % docker exec -it oracle-xe-11g bash . root@a702ae5d7f10:/# sqlplus . SQL*Plus: Release 11.2.0.2.0 Production on Sun Oct 27 02:33:24 2019 . Copyright (c) 1982, 2011, Oracle. All rights reserved. . Enter user-name: system Enter password: . Connected to: Oracle Database 11g Express Edition Release 11.2.0.2.0 - 64bit Production . SQL&gt; 제대로 모두 입력하여 sqlplus에 로그인까지 진행하면 이렇게 된다. . | . 도대체 pseudo-TTY가 뭐지? 에 대한 글은 다음 링크를 참고하자. . Bash Shell에 대한 엄청난 gitbook : TTY | 콘솔? 터미널? 쉘? | . - oracleinanutshell/oracle-xe-11g image로부터 Container를 실행하였고, Container에서 sqlplus를 실행해서 로그인도 해 봤다. - 설정을 다 했다. 그런데 컴퓨터 재부팅을 하거나, Docker를 종료했다가 Container를 또 실행하고 싶으면 어떻게 해야 할까? . -docker start oracle-xe-11g : 하나, 혹은 여러 개의 멈춘 Container를 실행한다. 여기서는 docker run으로 생성한 ‘oracle-xe-11g’ 라는 이름을 붙인 Container를 실행한다. . 뭐 하나 잊어버린 것 같은데..? : Volume . 그런데 여기서 빼먹은 것이 하나 있다. 위에 위험한 설명이 하나 있었던 것 같은데? . Container가 삭제될 때에는, 영구 저장소에 저장되지 않은 상태 변경 값은 사라진다. 그렇다. 모든 변경 사항은 Container의 R/W Layer에 저장되며, 이 Layer는 Container가 삭제되면 같이 사라진다. . Container를 영영 없애지 않을 생각이거나, 한 Container의 데이터를 다른 Container와 공유하지 않을 생각이라면 지금까지 입력한 명령어들만으로도 충분하다. 하지만 아니라면? Volume을 사용, 데이터를 Host에 저장하여 안전하게 유지, 공유해보자. 아래 두 링크를 꼭 읽어보자. 초반 부분만 읽어봐도 된다. . Docker 공식 페이지 / Use volumes | Docker 공식 페이지 / About storage drivers https://docs.docker.com/storage/volumes/ Volumes are the preferred mechanism for persisting data generated by and used by Docker Containers. . | . https://docs.docker.com/storage/storagedriver/#Container-and-layers The major difference between a Container and an image is the top writable layer. All writes to the Container that add new or modify existing data are stored in this writable layer. When the Container is deleted, the writable layer is also deleted. The underlying image remains unchanged. Because each Container has its own writable Container layer, and all changes are stored in this Container layer, multiple Containers can share access to the same underlying image and yet have their own data state. . 그럼, oracle-xe-11g Container 안의 어떤 폴더를 Host의 폴더와 연결해 주어야 할까? Container 안에서 oracle이란 이름을 가진 폴더를 검색해보자. . $ find / -name oracle -type d # 전체 폴더에서 oracle 이름을 가진 폴더 검색 /u01/app/oracle . 오호라, /u01/app/oracle를 연결하면 될 것 같다. . docker run문서에 따르면, Volume을 할당하기 위해 다음과 같은 옵션이 필요하다. -v [Host directory]:[Container directory] 이 옵션을 추가하여, Container를 다시 생성해 보자. . docker run --name oracle-xe-11g -d -p 8080:8080 -p 1521:1521 -v /Users/youngjinlim/Coding/BigData_Study/SQL/Docker_volume:/u01/app/oracle oracleinanutshell/oracle-xe-11g . 과연 Volume이 잘 Mount 되었을까? . % docker inspect --format=&#39;&#39; oracle-xe-11g [{bind /Users/youngjinlim/Coding/BigData_Study/SQL/Docker_volume /u01/app/oracle true rprivate}] . 오, 잘 연결된 것 같다. 그런데… DB에 연결할 수가 없었다! 왜지? . root@141d12eb18ac:/u01/app/oracle# ls -l total 0 . 어엉? Container 쪽 폴더가 텅 비어버렸다! 아무래도 Host쪽의 폴더로 덮어씌워진 것 같다. 아.. 너무 고통스럽다.. 이에 대한 원인과 해결방법은 이 블로그에서 찾을 수 있었다. . docker volume의 사용방법과 차이점 : !!주의!!&lt;/span&gt; 이 블로그 포스팅에선 docker create volume volume_name 라고 썼는데,이러면 안된다. 왜냐면.. | . https://docs.docker.com/engine/reference/commandline/create/ Description : Create a new Container Usage : docker create [OPTIONS] image [COMMAND] [ARG…] docker create는 Container를 만들 때 쓰는 명령어이기 때문이다. docker volume을 써야 한다. . Host쪽 폴더가 텅 비어있을 때, Container쪽 폴더를 남기려면 아래와 같은 방법을 사용해야 한다. . docker volume create volume_name docker run --name oracle-xe-11g -d -v volume_name:/Container/some/where ...(이하생략) . 그럼 실행해 보자. . % docker volume create oracle-xe-11g_study # Volume 생성 % docker volume ls # 잘 생성되었는지 확인 DRIVER VOLUME NAME local oracle-xe-11g_study % docker run --name oracle-xe-11g_study -d -v oracle-xe-11g_study:/u01/app/oracle -p 8080:8080 -p 1521:1521 oracleinanutshell/oracle-xe-11g 6a7d5728c9084c9f2c25931a8a7bf1120594776380d5cd8e17d6d15b48604eb6 # 새 Container 생성 % docker exec -it oracle-xe-11g_study bash # /u01/app/oracle 폴더 무사한지 확인하러 들어감 root@6a7d5728c908:/# cd /u01/app/oracle root@6a7d5728c908:/u01/app/oracle# ls -l # 결과를 보면 무사함을 알 수 있음 total 24 drwxr-x 4 oracle dba 4096 Oct 27 03:39 admin drwxrwxr-x 4 oracle dba 4096 Oct 27 03:39 diag drwxr-x 3 oracle dba 4096 Oct 27 03:39 fast_recovery_area drwxr-x 3 oracle dba 4096 Oct 27 03:39 oradata drwxr-xr-x 3 oracle dba 4096 Oct 27 03:39 oradiag_oracle drwxr-xr-x 3 root root 4096 Oct 27 03:39 product root@6a7d5728c908:/u01/app/oracle# exit exit % docker inspect --format=&#39;&#39; oracle-xe-11g_study # Volume 잘 연결 되었는지 확인 [{volume oracle-xe-11g_study /var/lib/docker/volumes/oracle-xe-11g_study/_data /u01/app/oracle local z true }] . 연결도 잘 됐고, Container 쪽 폴더도 무사하다. ‘CUSTOMERS’ 라는 이름의 테이블을 추가한 후, Container를 새로 생성해서 같은 Volume에 연결했을 경우, 새로 생성한 Container에서도 CUSTOMERS 테이블이 잘 보이는지 확인해 보자. . . % docker run --name oracle-xe-11g_volumetest -d -v oracle-xe-11g_study:/u01/app/oracle -p 8080:8080 -p 1521:1521 oracleinanutshell/oracle-xe-11g 08ba1459d196d6094b7adc2232d843e430574551cb1ba4c823fae7f85aa8fe36 youngjinlim@Youngui-MacBookPro ~ % docker ps ...중략 NAMES oracle-xe-11g_volumetest . 새로 생성한 Container 하나만 실행 중이다.(oracle-xe-11g_volumetest) 이제 추가했던 테이블이 그대로 있는지 확인해 보자. . . 잘 있다. . 일단 Mac에서 Oracle DB를 사용하기 위한 여정은 여기서 끝이다. Docker 마스터의 길은 멀고도 험하느니. . . 이번에 알아본 것 . Docker의 기본적인 개념 | Docker를 개념을 알아보다가 궁금해진 것들 궁금해진 것들 중 너무 큰 주제들이 많았는데, 별도로 정리를 할 필요가 있어 보인다. | . | Oracle Database 11g 설치 중 사용한 명령어들의 의미 Docker 공식문서가 최고다. 공식문서를 보시오 | . | .",
            "url": "https://limyj0708.github.io/fastpages/%ED%95%99%EC%8A%B5_%EC%A0%95%EB%A6%AC/2019/10/18/lets-start-docker-through-installing-oracle11g-on-mac.html",
            "relUrl": "/%ED%95%99%EC%8A%B5_%EC%A0%95%EB%A6%AC/2019/10/18/lets-start-docker-through-installing-oracle11g-on-mac.html",
            "date": " • Oct 18, 2019"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Email : limyj0708@gmail.com .",
          "url": "https://limyj0708.github.io/fastpages/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://limyj0708.github.io/fastpages/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}